{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "### model parameters\n",
    "\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "### training parameters\n",
    "\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 500\n",
    "\n",
    "# Amazon stock market\n",
    "ticker = \"AMZN\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        #df = si.get_data(ticker)\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        time.sleep(2)  # Add delay\n",
    "        df = si.get_data(ticker, headers=headers)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    \n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    \n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, input_shape=(sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ishan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0059 - mean_absolute_error: 0.0492\n",
      "Epoch 1: val_loss improved from inf to 0.00046, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 0.0058 - mean_absolute_error: 0.0488 - val_loss: 4.5804e-04 - val_mean_absolute_error: 0.0155\n",
      "Epoch 2/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 7.2669e-04 - mean_absolute_error: 0.0192\n",
      "Epoch 2: val_loss improved from 0.00046 to 0.00030, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 7.2480e-04 - mean_absolute_error: 0.0192 - val_loss: 2.9601e-04 - val_mean_absolute_error: 0.0122\n",
      "Epoch 3/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 6.9446e-04 - mean_absolute_error: 0.0189\n",
      "Epoch 3: val_loss did not improve from 0.00030\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 6.9487e-04 - mean_absolute_error: 0.0189 - val_loss: 3.2026e-04 - val_mean_absolute_error: 0.0141\n",
      "Epoch 4/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 5.8435e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 4: val_loss did not improve from 0.00030\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 5.8558e-04 - mean_absolute_error: 0.0173 - val_loss: 3.4829e-04 - val_mean_absolute_error: 0.0139\n",
      "Epoch 5/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 6.4701e-04 - mean_absolute_error: 0.0181\n",
      "Epoch 5: val_loss did not improve from 0.00030\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 6.4621e-04 - mean_absolute_error: 0.0181 - val_loss: 3.5547e-04 - val_mean_absolute_error: 0.0144\n",
      "Epoch 6/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 5.9911e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 6: val_loss did not improve from 0.00030\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 5.9881e-04 - mean_absolute_error: 0.0180 - val_loss: 3.0621e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 7/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 6.1638e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 7: val_loss did not improve from 0.00030\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 6.1603e-04 - mean_absolute_error: 0.0178 - val_loss: 3.8763e-04 - val_mean_absolute_error: 0.0143\n",
      "Epoch 8/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 6.4448e-04 - mean_absolute_error: 0.0176\n",
      "Epoch 8: val_loss did not improve from 0.00030\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 6.4326e-04 - mean_absolute_error: 0.0176 - val_loss: 3.8366e-04 - val_mean_absolute_error: 0.0174\n",
      "Epoch 9/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 6.6303e-04 - mean_absolute_error: 0.0192\n",
      "Epoch 9: val_loss did not improve from 0.00030\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 6.6290e-04 - mean_absolute_error: 0.0192 - val_loss: 3.0353e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 10/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 6.7978e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 10: val_loss did not improve from 0.00030\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 6.7945e-04 - mean_absolute_error: 0.0185 - val_loss: 3.1725e-04 - val_mean_absolute_error: 0.0140\n",
      "Epoch 11/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 5.5347e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 11: val_loss did not improve from 0.00030\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 5.5303e-04 - mean_absolute_error: 0.0171 - val_loss: 3.7949e-04 - val_mean_absolute_error: 0.0151\n",
      "Epoch 12/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 6.8851e-04 - mean_absolute_error: 0.0191\n",
      "Epoch 12: val_loss did not improve from 0.00030\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 6.8859e-04 - mean_absolute_error: 0.0191 - val_loss: 3.0078e-04 - val_mean_absolute_error: 0.0141\n",
      "Epoch 13/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 5.7485e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 13: val_loss improved from 0.00030 to 0.00029, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 5.7494e-04 - mean_absolute_error: 0.0174 - val_loss: 2.8992e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 14/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 5.7254e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 14: val_loss did not improve from 0.00029\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 5.7318e-04 - mean_absolute_error: 0.0178 - val_loss: 3.1350e-04 - val_mean_absolute_error: 0.0145\n",
      "Epoch 15/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 5.8257e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 15: val_loss did not improve from 0.00029\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 5.8268e-04 - mean_absolute_error: 0.0179 - val_loss: 3.9099e-04 - val_mean_absolute_error: 0.0145\n",
      "Epoch 16/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 5.8271e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 16: val_loss did not improve from 0.00029\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 5.8252e-04 - mean_absolute_error: 0.0178 - val_loss: 3.0478e-04 - val_mean_absolute_error: 0.0155\n",
      "Epoch 17/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 5.4317e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 17: val_loss did not improve from 0.00029\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 5.4310e-04 - mean_absolute_error: 0.0179 - val_loss: 3.3899e-04 - val_mean_absolute_error: 0.0145\n",
      "Epoch 18/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 5.4276e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 18: val_loss did not improve from 0.00029\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 5.4283e-04 - mean_absolute_error: 0.0179 - val_loss: 2.8999e-04 - val_mean_absolute_error: 0.0131\n",
      "Epoch 19/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 6.0038e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 19: val_loss did not improve from 0.00029\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - loss: 6.0037e-04 - mean_absolute_error: 0.0183 - val_loss: 3.0865e-04 - val_mean_absolute_error: 0.0153\n",
      "Epoch 20/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 5.3292e-04 - mean_absolute_error: 0.0181\n",
      "Epoch 20: val_loss improved from 0.00029 to 0.00028, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 5.3280e-04 - mean_absolute_error: 0.0181 - val_loss: 2.8167e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 21/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 5.4893e-04 - mean_absolute_error: 0.0177\n",
      "Epoch 21: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 5.4844e-04 - mean_absolute_error: 0.0177 - val_loss: 2.8210e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 22/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 5.6569e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 22: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 5.6524e-04 - mean_absolute_error: 0.0178 - val_loss: 2.8724e-04 - val_mean_absolute_error: 0.0116\n",
      "Epoch 23/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 5.2877e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 23: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 5.2962e-04 - mean_absolute_error: 0.0179 - val_loss: 2.8546e-04 - val_mean_absolute_error: 0.0125\n",
      "Epoch 24/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 5.4934e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 24: val_loss improved from 0.00028 to 0.00028, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 5.4927e-04 - mean_absolute_error: 0.0180 - val_loss: 2.8002e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 25/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 5.2055e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 25: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 127ms/step - loss: 5.2042e-04 - mean_absolute_error: 0.0174 - val_loss: 2.8762e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 26/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 5.1524e-04 - mean_absolute_error: 0.0176\n",
      "Epoch 26: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - loss: 5.1478e-04 - mean_absolute_error: 0.0176 - val_loss: 3.4586e-04 - val_mean_absolute_error: 0.0137\n",
      "Epoch 27/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 5.4981e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 27: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 5.4899e-04 - mean_absolute_error: 0.0179 - val_loss: 3.6170e-04 - val_mean_absolute_error: 0.0148\n",
      "Epoch 28/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 5.9921e-04 - mean_absolute_error: 0.0191\n",
      "Epoch 28: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 5.9845e-04 - mean_absolute_error: 0.0191 - val_loss: 2.8177e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 29/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 5.3504e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 29: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 5.3463e-04 - mean_absolute_error: 0.0179 - val_loss: 3.5291e-04 - val_mean_absolute_error: 0.0140\n",
      "Epoch 30/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 5.4000e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 30: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 5.3986e-04 - mean_absolute_error: 0.0182 - val_loss: 2.8384e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 31/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.9831e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 31: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.9838e-04 - mean_absolute_error: 0.0178 - val_loss: 2.8846e-04 - val_mean_absolute_error: 0.0129\n",
      "Epoch 32/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 5.0032e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 32: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - loss: 5.0003e-04 - mean_absolute_error: 0.0180 - val_loss: 2.8390e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 33/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.9965e-04 - mean_absolute_error: 0.0176\n",
      "Epoch 33: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.9985e-04 - mean_absolute_error: 0.0176 - val_loss: 3.1849e-04 - val_mean_absolute_error: 0.0130\n",
      "Epoch 34/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 5.2777e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 34: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 5.2690e-04 - mean_absolute_error: 0.0182 - val_loss: 2.9043e-04 - val_mean_absolute_error: 0.0123\n",
      "Epoch 35/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.9931e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 35: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.9956e-04 - mean_absolute_error: 0.0182 - val_loss: 3.5608e-04 - val_mean_absolute_error: 0.0136\n",
      "Epoch 36/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 5.0875e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 36: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 5.0854e-04 - mean_absolute_error: 0.0182 - val_loss: 3.1685e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 37/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 5.3838e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 37: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 5.3761e-04 - mean_absolute_error: 0.0182 - val_loss: 3.2136e-04 - val_mean_absolute_error: 0.0142\n",
      "Epoch 38/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 4.5172e-04 - mean_absolute_error: 0.0177\n",
      "Epoch 38: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 4.5182e-04 - mean_absolute_error: 0.0177 - val_loss: 3.0288e-04 - val_mean_absolute_error: 0.0130\n",
      "Epoch 39/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 5.3114e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 39: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 5.3045e-04 - mean_absolute_error: 0.0180 - val_loss: 2.8888e-04 - val_mean_absolute_error: 0.0135\n",
      "Epoch 40/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 4.9776e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 40: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 4.9749e-04 - mean_absolute_error: 0.0182 - val_loss: 2.9662e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 41/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 5.1222e-04 - mean_absolute_error: 0.0184\n",
      "Epoch 41: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - loss: 5.1226e-04 - mean_absolute_error: 0.0184 - val_loss: 2.9225e-04 - val_mean_absolute_error: 0.0122\n",
      "Epoch 42/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 5.1093e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 42: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 5.1058e-04 - mean_absolute_error: 0.0185 - val_loss: 2.9074e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 43/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.9859e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 43: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.9799e-04 - mean_absolute_error: 0.0179 - val_loss: 2.8993e-04 - val_mean_absolute_error: 0.0121\n",
      "Epoch 44/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.9270e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 44: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.9272e-04 - mean_absolute_error: 0.0183 - val_loss: 3.4372e-04 - val_mean_absolute_error: 0.0140\n",
      "Epoch 45/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 5.2873e-04 - mean_absolute_error: 0.0191\n",
      "Epoch 45: val_loss improved from 0.00028 to 0.00028, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 5.2846e-04 - mean_absolute_error: 0.0191 - val_loss: 2.7974e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 46/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 5.1697e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 46: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 5.1666e-04 - mean_absolute_error: 0.0183 - val_loss: 2.8462e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 47/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 5.2939e-04 - mean_absolute_error: 0.0184\n",
      "Epoch 47: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 5.2914e-04 - mean_absolute_error: 0.0184 - val_loss: 2.8924e-04 - val_mean_absolute_error: 0.0131\n",
      "Epoch 48/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.9734e-04 - mean_absolute_error: 0.0186\n",
      "Epoch 48: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.9689e-04 - mean_absolute_error: 0.0186 - val_loss: 3.4438e-04 - val_mean_absolute_error: 0.0146\n",
      "Epoch 49/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.8900e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 49: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.8917e-04 - mean_absolute_error: 0.0183 - val_loss: 3.0104e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 50/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 5.0320e-04 - mean_absolute_error: 0.0184\n",
      "Epoch 50: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 5.0230e-04 - mean_absolute_error: 0.0184 - val_loss: 3.6790e-04 - val_mean_absolute_error: 0.0133\n",
      "Epoch 51/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 5.1878e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 51: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 5.1771e-04 - mean_absolute_error: 0.0185 - val_loss: 2.8000e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 52/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.7735e-04 - mean_absolute_error: 0.0177\n",
      "Epoch 52: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.7709e-04 - mean_absolute_error: 0.0177 - val_loss: 2.8997e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 53/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.9310e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 53: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 4.9265e-04 - mean_absolute_error: 0.0182 - val_loss: 2.8504e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 54/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 5.2563e-04 - mean_absolute_error: 0.0188\n",
      "Epoch 54: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 5.2477e-04 - mean_absolute_error: 0.0188 - val_loss: 3.9056e-04 - val_mean_absolute_error: 0.0155\n",
      "Epoch 55/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 5.1144e-04 - mean_absolute_error: 0.0190\n",
      "Epoch 55: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 5.1125e-04 - mean_absolute_error: 0.0190 - val_loss: 2.7974e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 56/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 5.1813e-04 - mean_absolute_error: 0.0187\n",
      "Epoch 56: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 5.1704e-04 - mean_absolute_error: 0.0187 - val_loss: 3.0077e-04 - val_mean_absolute_error: 0.0119\n",
      "Epoch 57/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 5.1838e-04 - mean_absolute_error: 0.0184\n",
      "Epoch 57: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 5.1731e-04 - mean_absolute_error: 0.0184 - val_loss: 2.8660e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 58/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 5.2984e-04 - mean_absolute_error: 0.0187\n",
      "Epoch 58: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 5.2933e-04 - mean_absolute_error: 0.0187 - val_loss: 2.9758e-04 - val_mean_absolute_error: 0.0123\n",
      "Epoch 59/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.9381e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 59: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.9345e-04 - mean_absolute_error: 0.0182 - val_loss: 2.8828e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 60/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 4.8684e-04 - mean_absolute_error: 0.0187\n",
      "Epoch 60: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - loss: 4.8632e-04 - mean_absolute_error: 0.0187 - val_loss: 2.8669e-04 - val_mean_absolute_error: 0.0131\n",
      "Epoch 61/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.9377e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 61: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.9345e-04 - mean_absolute_error: 0.0182 - val_loss: 2.8881e-04 - val_mean_absolute_error: 0.0140\n",
      "Epoch 62/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.9276e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 62: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.9219e-04 - mean_absolute_error: 0.0182 - val_loss: 2.8732e-04 - val_mean_absolute_error: 0.0141\n",
      "Epoch 63/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 5.3306e-04 - mean_absolute_error: 0.0192\n",
      "Epoch 63: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 5.3244e-04 - mean_absolute_error: 0.0192 - val_loss: 3.5152e-04 - val_mean_absolute_error: 0.0130\n",
      "Epoch 64/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.9995e-04 - mean_absolute_error: 0.0184\n",
      "Epoch 64: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.9894e-04 - mean_absolute_error: 0.0184 - val_loss: 3.5302e-04 - val_mean_absolute_error: 0.0143\n",
      "Epoch 65/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.7647e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 65: val_loss improved from 0.00028 to 0.00028, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.7592e-04 - mean_absolute_error: 0.0182 - val_loss: 2.7901e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 66/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 4.9265e-04 - mean_absolute_error: 0.0184\n",
      "Epoch 66: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - loss: 4.9236e-04 - mean_absolute_error: 0.0183 - val_loss: 3.8731e-04 - val_mean_absolute_error: 0.0139\n",
      "Epoch 67/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.9216e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 67: val_loss improved from 0.00028 to 0.00028, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.9147e-04 - mean_absolute_error: 0.0182 - val_loss: 2.7751e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 68/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 5.4058e-04 - mean_absolute_error: 0.0190\n",
      "Epoch 68: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 5.4005e-04 - mean_absolute_error: 0.0190 - val_loss: 3.0228e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 69/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 4.7605e-04 - mean_absolute_error: 0.0181\n",
      "Epoch 69: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - loss: 4.7588e-04 - mean_absolute_error: 0.0181 - val_loss: 2.9686e-04 - val_mean_absolute_error: 0.0149\n",
      "Epoch 70/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 5.1824e-04 - mean_absolute_error: 0.0191\n",
      "Epoch 70: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 114ms/step - loss: 5.1749e-04 - mean_absolute_error: 0.0191 - val_loss: 3.0280e-04 - val_mean_absolute_error: 0.0152\n",
      "Epoch 71/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 4.9464e-04 - mean_absolute_error: 0.0189\n",
      "Epoch 71: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - loss: 4.9426e-04 - mean_absolute_error: 0.0189 - val_loss: 3.1056e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 72/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.8318e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 72: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 4.8296e-04 - mean_absolute_error: 0.0185 - val_loss: 2.8646e-04 - val_mean_absolute_error: 0.0141\n",
      "Epoch 73/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 5.1580e-04 - mean_absolute_error: 0.0189\n",
      "Epoch 73: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 5.1460e-04 - mean_absolute_error: 0.0188 - val_loss: 2.9092e-04 - val_mean_absolute_error: 0.0125\n",
      "Epoch 74/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.7655e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 74: val_loss improved from 0.00028 to 0.00028, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.7618e-04 - mean_absolute_error: 0.0182 - val_loss: 2.7661e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 75/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.4253e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 75: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.4224e-04 - mean_absolute_error: 0.0175 - val_loss: 3.2956e-04 - val_mean_absolute_error: 0.0138\n",
      "Epoch 76/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.7882e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 76: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 4.7823e-04 - mean_absolute_error: 0.0183 - val_loss: 3.1167e-04 - val_mean_absolute_error: 0.0122\n",
      "Epoch 77/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 4.7746e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 77: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 4.7711e-04 - mean_absolute_error: 0.0182 - val_loss: 2.9448e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 78/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.6336e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 78: val_loss improved from 0.00028 to 0.00028, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.6285e-04 - mean_absolute_error: 0.0178 - val_loss: 2.7566e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 79/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.8765e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 79: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.8718e-04 - mean_absolute_error: 0.0183 - val_loss: 3.3365e-04 - val_mean_absolute_error: 0.0125\n",
      "Epoch 80/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4.9636e-04 - mean_absolute_error: 0.0186\n",
      "Epoch 80: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 4.9638e-04 - mean_absolute_error: 0.0186 - val_loss: 2.7672e-04 - val_mean_absolute_error: 0.0121\n",
      "Epoch 81/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4.8347e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 81: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 4.8302e-04 - mean_absolute_error: 0.0182 - val_loss: 2.7987e-04 - val_mean_absolute_error: 0.0129\n",
      "Epoch 82/500\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.7341e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 82: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.7320e-04 - mean_absolute_error: 0.0182 - val_loss: 3.4020e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 83/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.9051e-04 - mean_absolute_error: 0.0186\n",
      "Epoch 83: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.8990e-04 - mean_absolute_error: 0.0186 - val_loss: 2.9276e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 84/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.8201e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 84: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.8129e-04 - mean_absolute_error: 0.0182 - val_loss: 2.7631e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 85/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4.7406e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 85: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 4.7356e-04 - mean_absolute_error: 0.0184 - val_loss: 2.8021e-04 - val_mean_absolute_error: 0.0131\n",
      "Epoch 86/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.6101e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 86: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.6096e-04 - mean_absolute_error: 0.0175 - val_loss: 2.7637e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 87/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 5.0109e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 87: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 5.0030e-04 - mean_absolute_error: 0.0183 - val_loss: 3.1545e-04 - val_mean_absolute_error: 0.0122\n",
      "Epoch 88/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4.8244e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 88: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 4.8226e-04 - mean_absolute_error: 0.0179 - val_loss: 3.5356e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 89/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.7988e-04 - mean_absolute_error: 0.0181\n",
      "Epoch 89: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.7953e-04 - mean_absolute_error: 0.0181 - val_loss: 2.8314e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 90/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4.3661e-04 - mean_absolute_error: 0.0176\n",
      "Epoch 90: val_loss improved from 0.00028 to 0.00028, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 4.3636e-04 - mean_absolute_error: 0.0176 - val_loss: 2.7514e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 91/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 5.0267e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 91: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 5.0205e-04 - mean_absolute_error: 0.0183 - val_loss: 2.8767e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 92/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4.7499e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 92: val_loss did not improve from 0.00028\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.7432e-04 - mean_absolute_error: 0.0183 - val_loss: 2.8690e-04 - val_mean_absolute_error: 0.0136\n",
      "Epoch 93/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.4658e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 93: val_loss improved from 0.00028 to 0.00027, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.4652e-04 - mean_absolute_error: 0.0178 - val_loss: 2.7258e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 94/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4.8302e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 94: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 4.8316e-04 - mean_absolute_error: 0.0182 - val_loss: 2.7481e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 95/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.7471e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 95: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.7417e-04 - mean_absolute_error: 0.0183 - val_loss: 2.9201e-04 - val_mean_absolute_error: 0.0119\n",
      "Epoch 96/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 4.7660e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 96: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 4.7601e-04 - mean_absolute_error: 0.0180 - val_loss: 2.8602e-04 - val_mean_absolute_error: 0.0141\n",
      "Epoch 97/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.7729e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 97: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 4.7674e-04 - mean_absolute_error: 0.0183 - val_loss: 2.7319e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 98/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.6714e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 98: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.6687e-04 - mean_absolute_error: 0.0178 - val_loss: 2.8042e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 99/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 5.2886e-04 - mean_absolute_error: 0.0188\n",
      "Epoch 99: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 5.2774e-04 - mean_absolute_error: 0.0188 - val_loss: 2.8567e-04 - val_mean_absolute_error: 0.0125\n",
      "Epoch 100/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 5.0629e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 100: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 5.0546e-04 - mean_absolute_error: 0.0183 - val_loss: 2.8725e-04 - val_mean_absolute_error: 0.0117\n",
      "Epoch 101/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 4.7027e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 101: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 4.6995e-04 - mean_absolute_error: 0.0180 - val_loss: 2.8031e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 102/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.7764e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 102: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.7715e-04 - mean_absolute_error: 0.0180 - val_loss: 3.3655e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 103/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.7454e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 103: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.7463e-04 - mean_absolute_error: 0.0180 - val_loss: 3.0446e-04 - val_mean_absolute_error: 0.0140\n",
      "Epoch 104/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.9225e-04 - mean_absolute_error: 0.0186\n",
      "Epoch 104: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.9131e-04 - mean_absolute_error: 0.0186 - val_loss: 2.8922e-04 - val_mean_absolute_error: 0.0131\n",
      "Epoch 105/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.6111e-04 - mean_absolute_error: 0.0176\n",
      "Epoch 105: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.6071e-04 - mean_absolute_error: 0.0176 - val_loss: 2.7811e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 106/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.7169e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 106: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.7141e-04 - mean_absolute_error: 0.0178 - val_loss: 3.6991e-04 - val_mean_absolute_error: 0.0130\n",
      "Epoch 107/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.6998e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 107: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 4.6943e-04 - mean_absolute_error: 0.0180 - val_loss: 2.7429e-04 - val_mean_absolute_error: 0.0116\n",
      "Epoch 108/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.4531e-04 - mean_absolute_error: 0.0176\n",
      "Epoch 108: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.4512e-04 - mean_absolute_error: 0.0176 - val_loss: 3.4167e-04 - val_mean_absolute_error: 0.0141\n",
      "Epoch 109/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.8247e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 109: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.8163e-04 - mean_absolute_error: 0.0183 - val_loss: 2.9666e-04 - val_mean_absolute_error: 0.0130\n",
      "Epoch 110/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.6656e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 110: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.6604e-04 - mean_absolute_error: 0.0178 - val_loss: 2.8815e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 111/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.5777e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 111: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.5733e-04 - mean_absolute_error: 0.0178 - val_loss: 2.8237e-04 - val_mean_absolute_error: 0.0116\n",
      "Epoch 112/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.8990e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 112: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.8905e-04 - mean_absolute_error: 0.0183 - val_loss: 4.1320e-04 - val_mean_absolute_error: 0.0135\n",
      "Epoch 113/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 5.2388e-04 - mean_absolute_error: 0.0188\n",
      "Epoch 113: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 5.2269e-04 - mean_absolute_error: 0.0188 - val_loss: 2.9280e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 114/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.6072e-04 - mean_absolute_error: 0.0177\n",
      "Epoch 114: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.6026e-04 - mean_absolute_error: 0.0177 - val_loss: 3.1678e-04 - val_mean_absolute_error: 0.0141\n",
      "Epoch 115/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.7496e-04 - mean_absolute_error: 0.0184\n",
      "Epoch 115: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 4.7421e-04 - mean_absolute_error: 0.0184 - val_loss: 3.2673e-04 - val_mean_absolute_error: 0.0138\n",
      "Epoch 116/500\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.5579e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 116: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.5554e-04 - mean_absolute_error: 0.0179 - val_loss: 2.7949e-04 - val_mean_absolute_error: 0.0131\n",
      "Epoch 117/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.7245e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 117: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 4.7175e-04 - mean_absolute_error: 0.0180 - val_loss: 3.3612e-04 - val_mean_absolute_error: 0.0141\n",
      "Epoch 118/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 5.1012e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 118: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 5.0915e-04 - mean_absolute_error: 0.0185 - val_loss: 2.9600e-04 - val_mean_absolute_error: 0.0142\n",
      "Epoch 119/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 4.6639e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 119: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 4.6584e-04 - mean_absolute_error: 0.0180 - val_loss: 3.0605e-04 - val_mean_absolute_error: 0.0134\n",
      "Epoch 120/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.9104e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 120: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.9055e-04 - mean_absolute_error: 0.0185 - val_loss: 2.8622e-04 - val_mean_absolute_error: 0.0140\n",
      "Epoch 121/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.8994e-04 - mean_absolute_error: 0.0184\n",
      "Epoch 121: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.8914e-04 - mean_absolute_error: 0.0184 - val_loss: 3.0590e-04 - val_mean_absolute_error: 0.0142\n",
      "Epoch 122/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.7063e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 122: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.7019e-04 - mean_absolute_error: 0.0182 - val_loss: 2.9942e-04 - val_mean_absolute_error: 0.0158\n",
      "Epoch 123/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.6756e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 123: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 4.6700e-04 - mean_absolute_error: 0.0185 - val_loss: 3.0648e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 124/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.7680e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 124: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 4.7616e-04 - mean_absolute_error: 0.0179 - val_loss: 3.0517e-04 - val_mean_absolute_error: 0.0122\n",
      "Epoch 125/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.5199e-04 - mean_absolute_error: 0.0177\n",
      "Epoch 125: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 4.5188e-04 - mean_absolute_error: 0.0177 - val_loss: 2.9673e-04 - val_mean_absolute_error: 0.0146\n",
      "Epoch 126/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.7128e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 126: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 4.7091e-04 - mean_absolute_error: 0.0178 - val_loss: 3.0214e-04 - val_mean_absolute_error: 0.0129\n",
      "Epoch 127/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.3760e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 127: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 4.3768e-04 - mean_absolute_error: 0.0174 - val_loss: 2.9875e-04 - val_mean_absolute_error: 0.0123\n",
      "Epoch 128/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.6831e-04 - mean_absolute_error: 0.0177\n",
      "Epoch 128: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 4.6816e-04 - mean_absolute_error: 0.0177 - val_loss: 3.4320e-04 - val_mean_absolute_error: 0.0122\n",
      "Epoch 129/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.6445e-04 - mean_absolute_error: 0.0176\n",
      "Epoch 129: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.6366e-04 - mean_absolute_error: 0.0176 - val_loss: 2.9821e-04 - val_mean_absolute_error: 0.0134\n",
      "Epoch 130/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.7647e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 130: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.7600e-04 - mean_absolute_error: 0.0179 - val_loss: 2.8790e-04 - val_mean_absolute_error: 0.0139\n",
      "Epoch 131/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.5401e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 131: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.5412e-04 - mean_absolute_error: 0.0180 - val_loss: 3.3448e-04 - val_mean_absolute_error: 0.0141\n",
      "Epoch 132/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.7310e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 132: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.7191e-04 - mean_absolute_error: 0.0180 - val_loss: 3.6273e-04 - val_mean_absolute_error: 0.0139\n",
      "Epoch 133/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 5.0722e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 133: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 5.0666e-04 - mean_absolute_error: 0.0185 - val_loss: 3.1719e-04 - val_mean_absolute_error: 0.0153\n",
      "Epoch 134/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.6322e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 134: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.6236e-04 - mean_absolute_error: 0.0177 - val_loss: 3.4348e-04 - val_mean_absolute_error: 0.0135\n",
      "Epoch 135/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.8168e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 135: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.8095e-04 - mean_absolute_error: 0.0182 - val_loss: 3.3881e-04 - val_mean_absolute_error: 0.0129\n",
      "Epoch 136/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.6804e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 136: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.6760e-04 - mean_absolute_error: 0.0178 - val_loss: 3.2712e-04 - val_mean_absolute_error: 0.0130\n",
      "Epoch 137/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.7788e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 137: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 4.7727e-04 - mean_absolute_error: 0.0179 - val_loss: 2.7517e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 138/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.2448e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 138: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.2409e-04 - mean_absolute_error: 0.0168 - val_loss: 2.9778e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 139/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.5874e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 139: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.5828e-04 - mean_absolute_error: 0.0175 - val_loss: 3.9635e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 140/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.5724e-04 - mean_absolute_error: 0.0176\n",
      "Epoch 140: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.5654e-04 - mean_absolute_error: 0.0176 - val_loss: 2.8052e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 141/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.1666e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 141: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.1672e-04 - mean_absolute_error: 0.0168 - val_loss: 2.8431e-04 - val_mean_absolute_error: 0.0116\n",
      "Epoch 142/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.7739e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 142: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.7709e-04 - mean_absolute_error: 0.0179 - val_loss: 3.3767e-04 - val_mean_absolute_error: 0.0144\n",
      "Epoch 143/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.8031e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 143: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 4.7992e-04 - mean_absolute_error: 0.0179 - val_loss: 3.3529e-04 - val_mean_absolute_error: 0.0135\n",
      "Epoch 144/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.9320e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 144: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 4.9236e-04 - mean_absolute_error: 0.0181 - val_loss: 2.8810e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 145/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.2581e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 145: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.2570e-04 - mean_absolute_error: 0.0174 - val_loss: 3.7616e-04 - val_mean_absolute_error: 0.0137\n",
      "Epoch 146/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.3935e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 146: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.3920e-04 - mean_absolute_error: 0.0173 - val_loss: 3.3654e-04 - val_mean_absolute_error: 0.0144\n",
      "Epoch 147/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 4.7629e-04 - mean_absolute_error: 0.0182\n",
      "Epoch 147: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 4.7550e-04 - mean_absolute_error: 0.0182 - val_loss: 3.1086e-04 - val_mean_absolute_error: 0.0122\n",
      "Epoch 148/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.4589e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 148: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 4.4517e-04 - mean_absolute_error: 0.0174 - val_loss: 2.8649e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 149/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.5982e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 149: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 4.5923e-04 - mean_absolute_error: 0.0173 - val_loss: 2.8282e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 150/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.2684e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 150: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.2622e-04 - mean_absolute_error: 0.0172 - val_loss: 3.5235e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 151/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.5159e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 151: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.5100e-04 - mean_absolute_error: 0.0175 - val_loss: 3.4414e-04 - val_mean_absolute_error: 0.0135\n",
      "Epoch 152/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.4233e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 152: val_loss improved from 0.00027 to 0.00027, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 4.4200e-04 - mean_absolute_error: 0.0175 - val_loss: 2.7222e-04 - val_mean_absolute_error: 0.0119\n",
      "Epoch 153/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.5592e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 153: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 4.5544e-04 - mean_absolute_error: 0.0175 - val_loss: 3.1487e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 154/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.8220e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 154: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 4.8145e-04 - mean_absolute_error: 0.0175 - val_loss: 3.4504e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 155/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 4.4662e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 155: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - loss: 4.4623e-04 - mean_absolute_error: 0.0172 - val_loss: 3.1109e-04 - val_mean_absolute_error: 0.0129\n",
      "Epoch 156/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.5643e-04 - mean_absolute_error: 0.0176\n",
      "Epoch 156: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 4.5568e-04 - mean_absolute_error: 0.0175 - val_loss: 2.9042e-04 - val_mean_absolute_error: 0.0119\n",
      "Epoch 157/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.4843e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 157: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.4809e-04 - mean_absolute_error: 0.0173 - val_loss: 3.2138e-04 - val_mean_absolute_error: 0.0129\n",
      "Epoch 158/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.4035e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 158: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.3974e-04 - mean_absolute_error: 0.0173 - val_loss: 2.8957e-04 - val_mean_absolute_error: 0.0121\n",
      "Epoch 159/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.9971e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 159: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.9847e-04 - mean_absolute_error: 0.0178 - val_loss: 3.0807e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 160/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.7264e-04 - mean_absolute_error: 0.0177\n",
      "Epoch 160: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.7219e-04 - mean_absolute_error: 0.0177 - val_loss: 3.4841e-04 - val_mean_absolute_error: 0.0143\n",
      "Epoch 161/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 4.7437e-04 - mean_absolute_error: 0.0177\n",
      "Epoch 161: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 4.7343e-04 - mean_absolute_error: 0.0177 - val_loss: 3.4823e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 162/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4.4628e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 162: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 4.4584e-04 - mean_absolute_error: 0.0175 - val_loss: 3.2151e-04 - val_mean_absolute_error: 0.0121\n",
      "Epoch 163/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.7453e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 163: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 4.7366e-04 - mean_absolute_error: 0.0175 - val_loss: 2.8208e-04 - val_mean_absolute_error: 0.0129\n",
      "Epoch 164/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.4096e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 164: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - loss: 4.4025e-04 - mean_absolute_error: 0.0172 - val_loss: 3.0305e-04 - val_mean_absolute_error: 0.0135\n",
      "Epoch 165/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.4752e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 165: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - loss: 4.4692e-04 - mean_absolute_error: 0.0172 - val_loss: 3.3528e-04 - val_mean_absolute_error: 0.0127\n",
      "Epoch 166/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.5250e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 166: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 4.5225e-04 - mean_absolute_error: 0.0173 - val_loss: 2.9508e-04 - val_mean_absolute_error: 0.0127\n",
      "Epoch 167/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.7484e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 167: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 4.7375e-04 - mean_absolute_error: 0.0178 - val_loss: 3.7243e-04 - val_mean_absolute_error: 0.0133\n",
      "Epoch 168/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.5375e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 168: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - loss: 4.5315e-04 - mean_absolute_error: 0.0175 - val_loss: 2.9158e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 169/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.2733e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 169: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - loss: 4.2703e-04 - mean_absolute_error: 0.0171 - val_loss: 2.7593e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 170/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.2480e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 170: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - loss: 4.2463e-04 - mean_absolute_error: 0.0170 - val_loss: 3.2406e-04 - val_mean_absolute_error: 0.0127\n",
      "Epoch 171/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4.3646e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 171: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - loss: 4.3577e-04 - mean_absolute_error: 0.0173 - val_loss: 3.1305e-04 - val_mean_absolute_error: 0.0140\n",
      "Epoch 172/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.3943e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 172: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - loss: 4.3905e-04 - mean_absolute_error: 0.0173 - val_loss: 2.8383e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 173/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.5588e-04 - mean_absolute_error: 0.0176\n",
      "Epoch 173: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - loss: 4.5518e-04 - mean_absolute_error: 0.0176 - val_loss: 3.2410e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 174/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.5894e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 174: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 4.5830e-04 - mean_absolute_error: 0.0174 - val_loss: 3.3019e-04 - val_mean_absolute_error: 0.0135\n",
      "Epoch 175/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4.5832e-04 - mean_absolute_error: 0.0177\n",
      "Epoch 175: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - loss: 4.5788e-04 - mean_absolute_error: 0.0177 - val_loss: 2.9546e-04 - val_mean_absolute_error: 0.0140\n",
      "Epoch 176/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.7794e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 176: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 4.7681e-04 - mean_absolute_error: 0.0178 - val_loss: 3.1612e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 177/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.5835e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 177: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - loss: 4.5776e-04 - mean_absolute_error: 0.0174 - val_loss: 3.1656e-04 - val_mean_absolute_error: 0.0119\n",
      "Epoch 178/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.4922e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 178: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - loss: 4.4841e-04 - mean_absolute_error: 0.0172 - val_loss: 2.9287e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 179/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.3509e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 179: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - loss: 4.3467e-04 - mean_absolute_error: 0.0170 - val_loss: 2.7367e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 180/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4.1688e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 180: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 4.1664e-04 - mean_absolute_error: 0.0170 - val_loss: 2.9004e-04 - val_mean_absolute_error: 0.0119\n",
      "Epoch 181/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.4519e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 181: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - loss: 4.4504e-04 - mean_absolute_error: 0.0174 - val_loss: 2.7662e-04 - val_mean_absolute_error: 0.0130\n",
      "Epoch 182/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.2975e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 182: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - loss: 4.2975e-04 - mean_absolute_error: 0.0173 - val_loss: 2.9043e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 183/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4.3869e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 183: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 4.3832e-04 - mean_absolute_error: 0.0173 - val_loss: 2.9726e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 184/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.4034e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 184: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 4.3987e-04 - mean_absolute_error: 0.0173 - val_loss: 3.0010e-04 - val_mean_absolute_error: 0.0125\n",
      "Epoch 185/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4.4035e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 185: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 4.3955e-04 - mean_absolute_error: 0.0171 - val_loss: 3.0107e-04 - val_mean_absolute_error: 0.0117\n",
      "Epoch 186/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4.4512e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 186: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - loss: 4.4458e-04 - mean_absolute_error: 0.0173 - val_loss: 2.9698e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 187/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4.2667e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 187: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 4.2619e-04 - mean_absolute_error: 0.0170 - val_loss: 3.4155e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 188/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4.6008e-04 - mean_absolute_error: 0.0177\n",
      "Epoch 188: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 4.5972e-04 - mean_absolute_error: 0.0177 - val_loss: 3.0515e-04 - val_mean_absolute_error: 0.0129\n",
      "Epoch 189/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4.2070e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 189: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 4.2029e-04 - mean_absolute_error: 0.0170 - val_loss: 3.3819e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 190/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.5364e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 190: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 4.5295e-04 - mean_absolute_error: 0.0175 - val_loss: 2.9701e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 191/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4.3266e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 191: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 4.3221e-04 - mean_absolute_error: 0.0171 - val_loss: 3.3574e-04 - val_mean_absolute_error: 0.0122\n",
      "Epoch 192/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.5424e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 192: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 4.5331e-04 - mean_absolute_error: 0.0173 - val_loss: 3.0608e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 193/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4.4801e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 193: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 4.4718e-04 - mean_absolute_error: 0.0172 - val_loss: 2.9744e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 194/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4.2727e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 194: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 4.2695e-04 - mean_absolute_error: 0.0170 - val_loss: 3.1998e-04 - val_mean_absolute_error: 0.0123\n",
      "Epoch 195/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4.7492e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 195: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - loss: 4.7400e-04 - mean_absolute_error: 0.0174 - val_loss: 3.0378e-04 - val_mean_absolute_error: 0.0130\n",
      "Epoch 196/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4.1208e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 196: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 4.1175e-04 - mean_absolute_error: 0.0168 - val_loss: 2.8530e-04 - val_mean_absolute_error: 0.0137\n",
      "Epoch 197/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4.2985e-04 - mean_absolute_error: 0.0176\n",
      "Epoch 197: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 4.2976e-04 - mean_absolute_error: 0.0176 - val_loss: 3.8110e-04 - val_mean_absolute_error: 0.0141\n",
      "Epoch 198/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4.5136e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 198: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - loss: 4.5060e-04 - mean_absolute_error: 0.0175 - val_loss: 2.9614e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 199/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.5188e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 199: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - loss: 4.5077e-04 - mean_absolute_error: 0.0174 - val_loss: 3.2560e-04 - val_mean_absolute_error: 0.0135\n",
      "Epoch 200/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4.3917e-04 - mean_absolute_error: 0.0174 \n",
      "Epoch 200: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 4.3852e-04 - mean_absolute_error: 0.0174 - val_loss: 3.1959e-04 - val_mean_absolute_error: 0.0127\n",
      "Epoch 201/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.1392e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 201: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 4.1363e-04 - mean_absolute_error: 0.0166 - val_loss: 2.9796e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 202/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4.2926e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 202: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - loss: 4.2900e-04 - mean_absolute_error: 0.0170 - val_loss: 3.2274e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 203/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.3884e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 203: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 4.3817e-04 - mean_absolute_error: 0.0172 - val_loss: 3.7912e-04 - val_mean_absolute_error: 0.0133\n",
      "Epoch 204/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4.5369e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 204: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 4.5287e-04 - mean_absolute_error: 0.0172 - val_loss: 2.8933e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 205/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4.3532e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 205: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - loss: 4.3484e-04 - mean_absolute_error: 0.0171 - val_loss: 3.2892e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 206/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4.2576e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 206: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 4.2512e-04 - mean_absolute_error: 0.0171 - val_loss: 3.2627e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 207/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.5475e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 207: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 4.5395e-04 - mean_absolute_error: 0.0178 - val_loss: 2.8757e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 208/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.2265e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 208: val_loss improved from 0.00027 to 0.00027, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 4.2225e-04 - mean_absolute_error: 0.0170 - val_loss: 2.6936e-04 - val_mean_absolute_error: 0.0117\n",
      "Epoch 209/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4.2636e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 209: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 4.2585e-04 - mean_absolute_error: 0.0169 - val_loss: 2.9517e-04 - val_mean_absolute_error: 0.0119\n",
      "Epoch 210/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.5129e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 210: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 4.5069e-04 - mean_absolute_error: 0.0172 - val_loss: 2.7503e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 211/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4.1722e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 211: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.1693e-04 - mean_absolute_error: 0.0167 - val_loss: 3.6808e-04 - val_mean_absolute_error: 0.0135\n",
      "Epoch 212/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4.2999e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 212: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - loss: 4.2918e-04 - mean_absolute_error: 0.0170 - val_loss: 2.8249e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 213/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.0384e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 213: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 4.0359e-04 - mean_absolute_error: 0.0165 - val_loss: 3.0083e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 214/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.4822e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 214: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 4.4751e-04 - mean_absolute_error: 0.0172 - val_loss: 3.1297e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 215/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4.1999e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 215: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 4.1962e-04 - mean_absolute_error: 0.0168 - val_loss: 3.1562e-04 - val_mean_absolute_error: 0.0119\n",
      "Epoch 216/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4.6481e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 216: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 4.6382e-04 - mean_absolute_error: 0.0175 - val_loss: 2.6936e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 217/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4.0588e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 217: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - loss: 4.0580e-04 - mean_absolute_error: 0.0169 - val_loss: 3.0413e-04 - val_mean_absolute_error: 0.0119\n",
      "Epoch 218/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4.2684e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 218: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 4.2616e-04 - mean_absolute_error: 0.0170 - val_loss: 3.1784e-04 - val_mean_absolute_error: 0.0117\n",
      "Epoch 219/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4.4942e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 219: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 4.4874e-04 - mean_absolute_error: 0.0173 - val_loss: 3.2613e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 220/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4.4346e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 220: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 4.4310e-04 - mean_absolute_error: 0.0173 - val_loss: 3.6169e-04 - val_mean_absolute_error: 0.0139\n",
      "Epoch 221/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.5550e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 221: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 4.5493e-04 - mean_absolute_error: 0.0175 - val_loss: 3.2541e-04 - val_mean_absolute_error: 0.0121\n",
      "Epoch 222/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.5877e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 222: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 4.5798e-04 - mean_absolute_error: 0.0174 - val_loss: 3.4132e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 223/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4.2541e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 223: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 4.2489e-04 - mean_absolute_error: 0.0171 - val_loss: 3.2466e-04 - val_mean_absolute_error: 0.0123\n",
      "Epoch 224/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.3824e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 224: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 4.3776e-04 - mean_absolute_error: 0.0171 - val_loss: 2.8282e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 225/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 3.9920e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 225: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 3.9911e-04 - mean_absolute_error: 0.0169 - val_loss: 2.8653e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 226/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4.1432e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 226: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 4.1393e-04 - mean_absolute_error: 0.0169 - val_loss: 2.8195e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 227/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4.0607e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 227: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 4.0584e-04 - mean_absolute_error: 0.0168 - val_loss: 3.0103e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 228/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4.1480e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 228: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 4.1465e-04 - mean_absolute_error: 0.0168 - val_loss: 2.8361e-04 - val_mean_absolute_error: 0.0130\n",
      "Epoch 229/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.1801e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 229: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 4.1744e-04 - mean_absolute_error: 0.0170 - val_loss: 2.7756e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 230/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.5144e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 230: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 4.5065e-04 - mean_absolute_error: 0.0175 - val_loss: 2.9274e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 231/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.3538e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 231: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 4.3474e-04 - mean_absolute_error: 0.0172 - val_loss: 2.8293e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 232/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 4.2237e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 232: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 4.2183e-04 - mean_absolute_error: 0.0169 - val_loss: 3.1446e-04 - val_mean_absolute_error: 0.0132\n",
      "Epoch 233/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 3.9880e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 233: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 3.9842e-04 - mean_absolute_error: 0.0166 - val_loss: 3.0692e-04 - val_mean_absolute_error: 0.0119\n",
      "Epoch 234/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4.4990e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 234: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 4.4889e-04 - mean_absolute_error: 0.0172 - val_loss: 3.2572e-04 - val_mean_absolute_error: 0.0121\n",
      "Epoch 235/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4.3501e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 235: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 4.3446e-04 - mean_absolute_error: 0.0170 - val_loss: 2.8316e-04 - val_mean_absolute_error: 0.0116\n",
      "Epoch 236/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.3793e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 236: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 4.3732e-04 - mean_absolute_error: 0.0169 - val_loss: 2.8974e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 237/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 4.1980e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 237: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 4.1923e-04 - mean_absolute_error: 0.0169 - val_loss: 2.7771e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 238/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 4.1852e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 238: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 4.1804e-04 - mean_absolute_error: 0.0166 - val_loss: 2.7721e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 239/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.1204e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 239: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 4.1157e-04 - mean_absolute_error: 0.0168 - val_loss: 2.8728e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 240/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.1877e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 240: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 4.1838e-04 - mean_absolute_error: 0.0170 - val_loss: 2.7167e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 241/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 3.9847e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 241: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 3.9845e-04 - mean_absolute_error: 0.0165 - val_loss: 3.2227e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 242/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.1785e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 242: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 4.1736e-04 - mean_absolute_error: 0.0171 - val_loss: 2.6949e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 243/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.0052e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 243: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 4.0019e-04 - mean_absolute_error: 0.0165 - val_loss: 2.7161e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 244/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 4.1067e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 244: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.1045e-04 - mean_absolute_error: 0.0166 - val_loss: 3.0275e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 245/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.1277e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 245: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.1257e-04 - mean_absolute_error: 0.0168 - val_loss: 3.7034e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 246/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4.1950e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 246: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 4.1889e-04 - mean_absolute_error: 0.0167 - val_loss: 3.2893e-04 - val_mean_absolute_error: 0.0123\n",
      "Epoch 247/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 3.7854e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 247: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 3.7831e-04 - mean_absolute_error: 0.0163 - val_loss: 2.7824e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 248/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4.1561e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 248: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.1525e-04 - mean_absolute_error: 0.0166 - val_loss: 3.3137e-04 - val_mean_absolute_error: 0.0122\n",
      "Epoch 249/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.1293e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 249: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 4.1262e-04 - mean_absolute_error: 0.0170 - val_loss: 3.0901e-04 - val_mean_absolute_error: 0.0117\n",
      "Epoch 250/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 4.2970e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 250: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 4.2957e-04 - mean_absolute_error: 0.0172 - val_loss: 3.5240e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 251/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4.5590e-04 - mean_absolute_error: 0.0176\n",
      "Epoch 251: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 4.5503e-04 - mean_absolute_error: 0.0176 - val_loss: 3.4784e-04 - val_mean_absolute_error: 0.0127\n",
      "Epoch 252/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 4.2402e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 252: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 4.2313e-04 - mean_absolute_error: 0.0169 - val_loss: 2.8663e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 253/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4.0250e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 253: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 4.0252e-04 - mean_absolute_error: 0.0163 - val_loss: 2.8506e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 254/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 3.8421e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 254: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 3.8402e-04 - mean_absolute_error: 0.0163 - val_loss: 3.0271e-04 - val_mean_absolute_error: 0.0127\n",
      "Epoch 255/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4.4206e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 255: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 4.4112e-04 - mean_absolute_error: 0.0173 - val_loss: 3.0749e-04 - val_mean_absolute_error: 0.0128\n",
      "Epoch 256/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.0787e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 256: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.0752e-04 - mean_absolute_error: 0.0170 - val_loss: 2.8417e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 257/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.3144e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 257: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 4.3088e-04 - mean_absolute_error: 0.0167 - val_loss: 2.7218e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 258/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.1781e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 258: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.1754e-04 - mean_absolute_error: 0.0169 - val_loss: 2.7974e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 259/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4.3126e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 259: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 4.3063e-04 - mean_absolute_error: 0.0167 - val_loss: 2.8393e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 260/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 4.1944e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 260: val_loss improved from 0.00027 to 0.00027, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.1887e-04 - mean_absolute_error: 0.0166 - val_loss: 2.6752e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 261/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.0578e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 261: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.0569e-04 - mean_absolute_error: 0.0166 - val_loss: 3.2428e-04 - val_mean_absolute_error: 0.0129\n",
      "Epoch 262/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 4.0682e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 262: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 4.0644e-04 - mean_absolute_error: 0.0168 - val_loss: 2.7152e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 263/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.2699e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 263: val_loss improved from 0.00027 to 0.00027, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.2644e-04 - mean_absolute_error: 0.0172 - val_loss: 2.6513e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 264/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 4.0376e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 264: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 4.0332e-04 - mean_absolute_error: 0.0166 - val_loss: 2.9934e-04 - val_mean_absolute_error: 0.0138\n",
      "Epoch 265/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 4.2404e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 265: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 4.2336e-04 - mean_absolute_error: 0.0169 - val_loss: 3.2235e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 266/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.2182e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 266: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.2116e-04 - mean_absolute_error: 0.0167 - val_loss: 3.0091e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 267/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 3.9733e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 267: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 3.9702e-04 - mean_absolute_error: 0.0164 - val_loss: 2.9068e-04 - val_mean_absolute_error: 0.0129\n",
      "Epoch 268/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 3.9349e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 268: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 3.9314e-04 - mean_absolute_error: 0.0165 - val_loss: 2.7145e-04 - val_mean_absolute_error: 0.0129\n",
      "Epoch 269/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.0103e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 269: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.0079e-04 - mean_absolute_error: 0.0167 - val_loss: 2.8025e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 270/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.1697e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 270: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.1641e-04 - mean_absolute_error: 0.0170 - val_loss: 3.0534e-04 - val_mean_absolute_error: 0.0151\n",
      "Epoch 271/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.1969e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 271: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.1937e-04 - mean_absolute_error: 0.0171 - val_loss: 2.7037e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 272/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 3.9615e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 272: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - loss: 3.9594e-04 - mean_absolute_error: 0.0162 - val_loss: 2.7447e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 273/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 4.2072e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 273: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - loss: 4.2040e-04 - mean_absolute_error: 0.0168 - val_loss: 2.6717e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 274/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4.2304e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 274: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.2219e-04 - mean_absolute_error: 0.0170 - val_loss: 2.9327e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 275/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 3.8637e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 275: val_loss did not improve from 0.00027\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 3.8619e-04 - mean_absolute_error: 0.0164 - val_loss: 3.1866e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 276/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.2440e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 276: val_loss improved from 0.00027 to 0.00026, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 4.2367e-04 - mean_absolute_error: 0.0170 - val_loss: 2.5965e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 277/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 3.8535e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 277: val_loss did not improve from 0.00026\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 3.8506e-04 - mean_absolute_error: 0.0163 - val_loss: 2.7066e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 278/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.0959e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 278: val_loss improved from 0.00026 to 0.00025, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.0908e-04 - mean_absolute_error: 0.0164 - val_loss: 2.4972e-04 - val_mean_absolute_error: 0.0107\n",
      "Epoch 279/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 4.0239e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 279: val_loss did not improve from 0.00025\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 4.0221e-04 - mean_absolute_error: 0.0169 - val_loss: 2.9000e-04 - val_mean_absolute_error: 0.0122\n",
      "Epoch 280/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.1418e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 280: val_loss did not improve from 0.00025\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.1357e-04 - mean_absolute_error: 0.0169 - val_loss: 3.3002e-04 - val_mean_absolute_error: 0.0125\n",
      "Epoch 281/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.0591e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 281: val_loss did not improve from 0.00025\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.0533e-04 - mean_absolute_error: 0.0165 - val_loss: 2.6738e-04 - val_mean_absolute_error: 0.0109\n",
      "Epoch 282/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.0066e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 282: val_loss did not improve from 0.00025\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.0028e-04 - mean_absolute_error: 0.0165 - val_loss: 2.7242e-04 - val_mean_absolute_error: 0.0125\n",
      "Epoch 283/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4.0399e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 283: val_loss did not improve from 0.00025\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 4.0357e-04 - mean_absolute_error: 0.0168 - val_loss: 2.6503e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 284/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.3147e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 284: val_loss did not improve from 0.00025\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 4.3070e-04 - mean_absolute_error: 0.0170 - val_loss: 2.9084e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 285/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4.2727e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 285: val_loss did not improve from 0.00025\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 4.2643e-04 - mean_absolute_error: 0.0169 - val_loss: 3.1522e-04 - val_mean_absolute_error: 0.0125\n",
      "Epoch 286/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 3.9613e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 286: val_loss improved from 0.00025 to 0.00024, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 3.9571e-04 - mean_absolute_error: 0.0164 - val_loss: 2.4333e-04 - val_mean_absolute_error: 0.0105\n",
      "Epoch 287/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.9689e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 287: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 3.9655e-04 - mean_absolute_error: 0.0162 - val_loss: 2.6387e-04 - val_mean_absolute_error: 0.0121\n",
      "Epoch 288/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.2030e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 288: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - loss: 4.2011e-04 - mean_absolute_error: 0.0169 - val_loss: 3.3847e-04 - val_mean_absolute_error: 0.0145\n",
      "Epoch 289/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.3644e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 289: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 4.3574e-04 - mean_absolute_error: 0.0171 - val_loss: 2.8370e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 290/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.1453e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 290: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.1402e-04 - mean_absolute_error: 0.0166 - val_loss: 2.6516e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 291/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.0058e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 291: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 3.9991e-04 - mean_absolute_error: 0.0164 - val_loss: 2.7773e-04 - val_mean_absolute_error: 0.0119\n",
      "Epoch 292/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.4330e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 292: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.4222e-04 - mean_absolute_error: 0.0171 - val_loss: 2.5693e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 293/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 3.8343e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 293: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 3.8301e-04 - mean_absolute_error: 0.0161 - val_loss: 3.4212e-04 - val_mean_absolute_error: 0.0146\n",
      "Epoch 294/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.0143e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 294: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.0107e-04 - mean_absolute_error: 0.0169 - val_loss: 2.4589e-04 - val_mean_absolute_error: 0.0107\n",
      "Epoch 295/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 3.9362e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 295: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 3.9318e-04 - mean_absolute_error: 0.0165 - val_loss: 2.6612e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 296/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 3.9543e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 296: val_loss improved from 0.00024 to 0.00024, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 3.9486e-04 - mean_absolute_error: 0.0166 - val_loss: 2.3593e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 297/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.9498e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 297: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - loss: 3.9464e-04 - mean_absolute_error: 0.0164 - val_loss: 2.8262e-04 - val_mean_absolute_error: 0.0133\n",
      "Epoch 298/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 3.8606e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 298: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 3.8515e-04 - mean_absolute_error: 0.0160 - val_loss: 2.7344e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 299/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.0984e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 299: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.0903e-04 - mean_absolute_error: 0.0167 - val_loss: 2.6209e-04 - val_mean_absolute_error: 0.0123\n",
      "Epoch 300/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 3.9065e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 300: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 3.9013e-04 - mean_absolute_error: 0.0165 - val_loss: 2.3904e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 301/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.0266e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 301: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.0218e-04 - mean_absolute_error: 0.0165 - val_loss: 2.4763e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 302/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 3.7403e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 302: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.7382e-04 - mean_absolute_error: 0.0164 - val_loss: 2.5926e-04 - val_mean_absolute_error: 0.0117\n",
      "Epoch 303/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 3.9214e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 303: val_loss did not improve from 0.00024\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 3.9144e-04 - mean_absolute_error: 0.0164 - val_loss: 2.7498e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 304/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 3.9575e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 304: val_loss improved from 0.00024 to 0.00023, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 3.9521e-04 - mean_absolute_error: 0.0164 - val_loss: 2.3379e-04 - val_mean_absolute_error: 0.0110\n",
      "Epoch 305/500\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.8156e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 305: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - loss: 3.8128e-04 - mean_absolute_error: 0.0163 - val_loss: 2.4608e-04 - val_mean_absolute_error: 0.0109\n",
      "Epoch 306/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 3.8896e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 306: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 3.8826e-04 - mean_absolute_error: 0.0165 - val_loss: 2.9395e-04 - val_mean_absolute_error: 0.0117\n",
      "Epoch 307/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.2763e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 307: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.2693e-04 - mean_absolute_error: 0.0174 - val_loss: 2.6532e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 308/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 3.8569e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 308: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 3.8527e-04 - mean_absolute_error: 0.0162 - val_loss: 2.9604e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 309/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.0927e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 309: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.0848e-04 - mean_absolute_error: 0.0166 - val_loss: 2.4255e-04 - val_mean_absolute_error: 0.0107\n",
      "Epoch 310/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.9142e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 310: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 3.9079e-04 - mean_absolute_error: 0.0164 - val_loss: 2.5917e-04 - val_mean_absolute_error: 0.0122\n",
      "Epoch 311/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.8652e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 311: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 3.8598e-04 - mean_absolute_error: 0.0163 - val_loss: 3.0072e-04 - val_mean_absolute_error: 0.0117\n",
      "Epoch 312/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.1928e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 312: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.1818e-04 - mean_absolute_error: 0.0168 - val_loss: 2.6623e-04 - val_mean_absolute_error: 0.0110\n",
      "Epoch 313/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 3.7803e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 313: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 3.7766e-04 - mean_absolute_error: 0.0160 - val_loss: 2.4583e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 314/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.7723e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 314: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 3.7712e-04 - mean_absolute_error: 0.0162 - val_loss: 2.4418e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 315/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 3.7030e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 315: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 3.6959e-04 - mean_absolute_error: 0.0161 - val_loss: 2.6768e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 316/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.9238e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 316: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 3.9180e-04 - mean_absolute_error: 0.0163 - val_loss: 2.3678e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 317/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.9003e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 317: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.8936e-04 - mean_absolute_error: 0.0164 - val_loss: 2.5076e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 318/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.6731e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 318: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 3.6711e-04 - mean_absolute_error: 0.0161 - val_loss: 3.2713e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 319/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.4134e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 319: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 4.3991e-04 - mean_absolute_error: 0.0172 - val_loss: 2.4345e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 320/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 3.8829e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 320: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 3.8792e-04 - mean_absolute_error: 0.0163 - val_loss: 2.5966e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 321/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.8788e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 321: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 3.8730e-04 - mean_absolute_error: 0.0162 - val_loss: 2.6254e-04 - val_mean_absolute_error: 0.0125\n",
      "Epoch 322/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.0699e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 322: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.0641e-04 - mean_absolute_error: 0.0170 - val_loss: 2.4705e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 323/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.8665e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 323: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 3.8618e-04 - mean_absolute_error: 0.0160 - val_loss: 2.4382e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 324/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 3.9764e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 324: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 3.9690e-04 - mean_absolute_error: 0.0165 - val_loss: 2.3533e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 325/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.5047e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 325: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 3.5017e-04 - mean_absolute_error: 0.0157 - val_loss: 2.5613e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 326/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.9786e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 326: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 3.9705e-04 - mean_absolute_error: 0.0165 - val_loss: 2.8198e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 327/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.0595e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 327: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 4.0521e-04 - mean_absolute_error: 0.0165 - val_loss: 2.5868e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 328/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 3.9486e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 328: val_loss improved from 0.00023 to 0.00023, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 3.9418e-04 - mean_absolute_error: 0.0166 - val_loss: 2.2749e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 329/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.7382e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 329: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 3.7322e-04 - mean_absolute_error: 0.0161 - val_loss: 2.5329e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 330/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.6910e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 330: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 3.6866e-04 - mean_absolute_error: 0.0161 - val_loss: 2.4639e-04 - val_mean_absolute_error: 0.0110\n",
      "Epoch 331/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 3.8927e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 331: val_loss did not improve from 0.00023\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 3.8873e-04 - mean_absolute_error: 0.0161 - val_loss: 2.5661e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 332/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 3.9326e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 332: val_loss improved from 0.00023 to 0.00022, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 3.9278e-04 - mean_absolute_error: 0.0165 - val_loss: 2.2465e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 333/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 3.6629e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 333: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 3.6550e-04 - mean_absolute_error: 0.0158 - val_loss: 3.3479e-04 - val_mean_absolute_error: 0.0145\n",
      "Epoch 334/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 3.7547e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 334: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 3.7500e-04 - mean_absolute_error: 0.0166 - val_loss: 2.4818e-04 - val_mean_absolute_error: 0.0107\n",
      "Epoch 335/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.8338e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 335: val_loss improved from 0.00022 to 0.00022, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 3.8260e-04 - mean_absolute_error: 0.0162 - val_loss: 2.2407e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 336/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.9241e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 336: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 3.9158e-04 - mean_absolute_error: 0.0163 - val_loss: 2.3106e-04 - val_mean_absolute_error: 0.0110\n",
      "Epoch 337/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.5993e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 337: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 3.5950e-04 - mean_absolute_error: 0.0162 - val_loss: 2.5065e-04 - val_mean_absolute_error: 0.0116\n",
      "Epoch 338/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.9957e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 338: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.9883e-04 - mean_absolute_error: 0.0165 - val_loss: 2.7106e-04 - val_mean_absolute_error: 0.0123\n",
      "Epoch 339/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 3.8752e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 339: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 3.8682e-04 - mean_absolute_error: 0.0160 - val_loss: 2.3839e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 340/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.6067e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 340: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 3.6031e-04 - mean_absolute_error: 0.0158 - val_loss: 2.7638e-04 - val_mean_absolute_error: 0.0110\n",
      "Epoch 341/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.7693e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 341: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 3.7650e-04 - mean_absolute_error: 0.0158 - val_loss: 2.5882e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 342/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.8888e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 342: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 3.8817e-04 - mean_absolute_error: 0.0163 - val_loss: 2.6931e-04 - val_mean_absolute_error: 0.0109\n",
      "Epoch 343/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.0575e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 343: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 4.0482e-04 - mean_absolute_error: 0.0165 - val_loss: 2.2417e-04 - val_mean_absolute_error: 0.0103\n",
      "Epoch 344/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 3.7373e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 344: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 3.7334e-04 - mean_absolute_error: 0.0160 - val_loss: 3.1082e-04 - val_mean_absolute_error: 0.0130\n",
      "Epoch 345/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.0102e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 345: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 4.0023e-04 - mean_absolute_error: 0.0164 - val_loss: 2.4778e-04 - val_mean_absolute_error: 0.0105\n",
      "Epoch 346/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.8729e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 346: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 3.8686e-04 - mean_absolute_error: 0.0163 - val_loss: 2.7925e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 347/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.0298e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 347: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - loss: 4.0204e-04 - mean_absolute_error: 0.0165 - val_loss: 2.6747e-04 - val_mean_absolute_error: 0.0125\n",
      "Epoch 348/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.9601e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 348: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 3.9560e-04 - mean_absolute_error: 0.0164 - val_loss: 2.3935e-04 - val_mean_absolute_error: 0.0110\n",
      "Epoch 349/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.7752e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 349: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 3.7689e-04 - mean_absolute_error: 0.0159 - val_loss: 2.3931e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 350/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.9472e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 350: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 3.9403e-04 - mean_absolute_error: 0.0165 - val_loss: 2.2429e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 351/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 3.5550e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 351: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 3.5514e-04 - mean_absolute_error: 0.0159 - val_loss: 2.7190e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 352/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.7998e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 352: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 3.7922e-04 - mean_absolute_error: 0.0159 - val_loss: 2.3330e-04 - val_mean_absolute_error: 0.0119\n",
      "Epoch 353/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.7520e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 353: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 3.7474e-04 - mean_absolute_error: 0.0159 - val_loss: 2.3335e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 354/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.8481e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 354: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 3.8408e-04 - mean_absolute_error: 0.0163 - val_loss: 2.3690e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 355/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 3.7351e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 355: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - loss: 3.7269e-04 - mean_absolute_error: 0.0160 - val_loss: 2.2586e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 356/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.7228e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 356: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 3.7164e-04 - mean_absolute_error: 0.0161 - val_loss: 2.5296e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 357/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.8579e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 357: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 3.8531e-04 - mean_absolute_error: 0.0164 - val_loss: 3.1204e-04 - val_mean_absolute_error: 0.0125\n",
      "Epoch 358/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 3.8123e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 358: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - loss: 3.8064e-04 - mean_absolute_error: 0.0162 - val_loss: 2.6779e-04 - val_mean_absolute_error: 0.0117\n",
      "Epoch 359/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.6292e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 359: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.6263e-04 - mean_absolute_error: 0.0160 - val_loss: 2.3367e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 360/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.6676e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 360: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 3.6631e-04 - mean_absolute_error: 0.0160 - val_loss: 2.4673e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 361/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.8591e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 361: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 3.8523e-04 - mean_absolute_error: 0.0163 - val_loss: 2.4026e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 362/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 4.0010e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 362: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 3.9921e-04 - mean_absolute_error: 0.0166 - val_loss: 2.2494e-04 - val_mean_absolute_error: 0.0117\n",
      "Epoch 363/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.6741e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 363: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 3.6711e-04 - mean_absolute_error: 0.0160 - val_loss: 2.4951e-04 - val_mean_absolute_error: 0.0116\n",
      "Epoch 364/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.8754e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 364: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 3.8688e-04 - mean_absolute_error: 0.0163 - val_loss: 2.6249e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 365/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.7132e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 365: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - loss: 3.7079e-04 - mean_absolute_error: 0.0159 - val_loss: 2.4346e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 366/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.8688e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 366: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 3.8619e-04 - mean_absolute_error: 0.0162 - val_loss: 2.5385e-04 - val_mean_absolute_error: 0.0110\n",
      "Epoch 367/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.6616e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 367: val_loss improved from 0.00022 to 0.00022, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - loss: 3.6550e-04 - mean_absolute_error: 0.0159 - val_loss: 2.2391e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 368/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.4899e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 368: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 3.4862e-04 - mean_absolute_error: 0.0157 - val_loss: 2.4111e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 369/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.5144e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 369: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 3.5120e-04 - mean_absolute_error: 0.0157 - val_loss: 2.7021e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 370/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.6696e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 370: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 3.6655e-04 - mean_absolute_error: 0.0159 - val_loss: 2.7579e-04 - val_mean_absolute_error: 0.0110\n",
      "Epoch 371/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 3.9843e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 371: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 3.9776e-04 - mean_absolute_error: 0.0161 - val_loss: 2.4587e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 372/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.6278e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 372: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 3.6251e-04 - mean_absolute_error: 0.0157 - val_loss: 2.6247e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 373/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.8894e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 373: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 3.8808e-04 - mean_absolute_error: 0.0163 - val_loss: 2.5430e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 374/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.1157e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 374: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 4.1075e-04 - mean_absolute_error: 0.0168 - val_loss: 2.3210e-04 - val_mean_absolute_error: 0.0103\n",
      "Epoch 375/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.6217e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 375: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 3.6189e-04 - mean_absolute_error: 0.0157 - val_loss: 2.5152e-04 - val_mean_absolute_error: 0.0109\n",
      "Epoch 376/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.5634e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 376: val_loss improved from 0.00022 to 0.00022, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - loss: 3.5595e-04 - mean_absolute_error: 0.0158 - val_loss: 2.2072e-04 - val_mean_absolute_error: 0.0101\n",
      "Epoch 377/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 3.7204e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 377: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.7151e-04 - mean_absolute_error: 0.0161 - val_loss: 2.4608e-04 - val_mean_absolute_error: 0.0123\n",
      "Epoch 378/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 3.7836e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 378: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - loss: 3.7773e-04 - mean_absolute_error: 0.0160 - val_loss: 2.4893e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 379/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.6083e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 379: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 3.6041e-04 - mean_absolute_error: 0.0157 - val_loss: 2.2947e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 380/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.7174e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 380: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 3.7103e-04 - mean_absolute_error: 0.0159 - val_loss: 2.2482e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 381/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.5098e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 381: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 3.5088e-04 - mean_absolute_error: 0.0159 - val_loss: 2.3968e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 382/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.9643e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 382: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 3.9573e-04 - mean_absolute_error: 0.0165 - val_loss: 2.3076e-04 - val_mean_absolute_error: 0.0105\n",
      "Epoch 383/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.6756e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 383: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.6711e-04 - mean_absolute_error: 0.0158 - val_loss: 2.5565e-04 - val_mean_absolute_error: 0.0109\n",
      "Epoch 384/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 3.7729e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 384: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - loss: 3.7667e-04 - mean_absolute_error: 0.0161 - val_loss: 2.3206e-04 - val_mean_absolute_error: 0.0107\n",
      "Epoch 385/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.8367e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 385: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - loss: 3.8294e-04 - mean_absolute_error: 0.0161 - val_loss: 2.3464e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 386/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 3.5883e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 386: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - loss: 3.5830e-04 - mean_absolute_error: 0.0156 - val_loss: 2.2359e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 387/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 3.8056e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 387: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - loss: 3.8011e-04 - mean_absolute_error: 0.0162 - val_loss: 2.3834e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 388/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.7733e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 388: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.7697e-04 - mean_absolute_error: 0.0163 - val_loss: 2.5492e-04 - val_mean_absolute_error: 0.0107\n",
      "Epoch 389/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.9114e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 389: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.9047e-04 - mean_absolute_error: 0.0164 - val_loss: 2.3872e-04 - val_mean_absolute_error: 0.0117\n",
      "Epoch 390/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 3.9384e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 390: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - loss: 3.9304e-04 - mean_absolute_error: 0.0165 - val_loss: 2.3380e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 391/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.8164e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 391: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - loss: 3.8096e-04 - mean_absolute_error: 0.0163 - val_loss: 2.2780e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 392/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.7024e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 392: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - loss: 3.6948e-04 - mean_absolute_error: 0.0161 - val_loss: 2.4375e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 393/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.9125e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 393: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.9051e-04 - mean_absolute_error: 0.0162 - val_loss: 2.5025e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 394/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 3.6944e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 394: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 3.6899e-04 - mean_absolute_error: 0.0159 - val_loss: 2.5921e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 395/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 3.7513e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 395: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - loss: 3.7463e-04 - mean_absolute_error: 0.0158 - val_loss: 2.3680e-04 - val_mean_absolute_error: 0.0110\n",
      "Epoch 396/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.6422e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 396: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.6386e-04 - mean_absolute_error: 0.0161 - val_loss: 2.6030e-04 - val_mean_absolute_error: 0.0122\n",
      "Epoch 397/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 4.0325e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 397: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - loss: 4.0217e-04 - mean_absolute_error: 0.0166 - val_loss: 2.5899e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 398/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 3.7100e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 398: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.7045e-04 - mean_absolute_error: 0.0159 - val_loss: 2.7607e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 399/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 3.7883e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 399: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - loss: 3.7828e-04 - mean_absolute_error: 0.0162 - val_loss: 2.4027e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 400/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.5411e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 400: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.5393e-04 - mean_absolute_error: 0.0157 - val_loss: 2.4461e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 401/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.5372e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 401: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.5314e-04 - mean_absolute_error: 0.0156 - val_loss: 2.3904e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 402/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.8947e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 402: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - loss: 3.8895e-04 - mean_absolute_error: 0.0163 - val_loss: 3.0641e-04 - val_mean_absolute_error: 0.0131\n",
      "Epoch 403/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 4.3059e-04 - mean_absolute_error: 0.0173\n",
      "Epoch 403: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 4.2936e-04 - mean_absolute_error: 0.0173 - val_loss: 2.2522e-04 - val_mean_absolute_error: 0.0105\n",
      "Epoch 404/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.4018e-04 - mean_absolute_error: 0.0155\n",
      "Epoch 404: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.4024e-04 - mean_absolute_error: 0.0155 - val_loss: 2.7643e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 405/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 3.7181e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 405: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - loss: 3.7125e-04 - mean_absolute_error: 0.0161 - val_loss: 2.4392e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 406/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.4505e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 406: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.4493e-04 - mean_absolute_error: 0.0158 - val_loss: 2.2770e-04 - val_mean_absolute_error: 0.0105\n",
      "Epoch 407/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.6056e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 407: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.6021e-04 - mean_absolute_error: 0.0157 - val_loss: 2.4486e-04 - val_mean_absolute_error: 0.0119\n",
      "Epoch 408/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.6838e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 408: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.6798e-04 - mean_absolute_error: 0.0161 - val_loss: 2.4031e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 409/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 3.7293e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 409: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.7247e-04 - mean_absolute_error: 0.0161 - val_loss: 2.8341e-04 - val_mean_absolute_error: 0.0118\n",
      "Epoch 410/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.7950e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 410: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - loss: 3.7868e-04 - mean_absolute_error: 0.0158 - val_loss: 2.5590e-04 - val_mean_absolute_error: 0.0109\n",
      "Epoch 411/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 4.0450e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 411: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 4.0359e-04 - mean_absolute_error: 0.0164 - val_loss: 2.4024e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 412/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.7562e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 412: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.7484e-04 - mean_absolute_error: 0.0159 - val_loss: 2.5465e-04 - val_mean_absolute_error: 0.0121\n",
      "Epoch 413/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.6162e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 413: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.6107e-04 - mean_absolute_error: 0.0159 - val_loss: 2.3745e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 414/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.6795e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 414: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.6752e-04 - mean_absolute_error: 0.0158 - val_loss: 2.3322e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 415/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 3.8505e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 415: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - loss: 3.8444e-04 - mean_absolute_error: 0.0163 - val_loss: 2.4023e-04 - val_mean_absolute_error: 0.0117\n",
      "Epoch 416/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 3.9055e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 416: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.8979e-04 - mean_absolute_error: 0.0163 - val_loss: 2.5492e-04 - val_mean_absolute_error: 0.0116\n",
      "Epoch 417/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 3.8274e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 417: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 3.8198e-04 - mean_absolute_error: 0.0163 - val_loss: 2.4968e-04 - val_mean_absolute_error: 0.0110\n",
      "Epoch 418/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.8563e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 418: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.8492e-04 - mean_absolute_error: 0.0162 - val_loss: 2.2475e-04 - val_mean_absolute_error: 0.0105\n",
      "Epoch 419/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.6522e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 419: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.6479e-04 - mean_absolute_error: 0.0160 - val_loss: 2.6024e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 420/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.9701e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 420: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.9608e-04 - mean_absolute_error: 0.0165 - val_loss: 2.4787e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 421/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 3.5866e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 421: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - loss: 3.5805e-04 - mean_absolute_error: 0.0158 - val_loss: 2.2282e-04 - val_mean_absolute_error: 0.0107\n",
      "Epoch 422/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.5937e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 422: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.5885e-04 - mean_absolute_error: 0.0157 - val_loss: 2.5135e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 423/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.6053e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 423: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.5996e-04 - mean_absolute_error: 0.0158 - val_loss: 2.2718e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 424/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 3.7367e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 424: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 3.7341e-04 - mean_absolute_error: 0.0162 - val_loss: 2.5666e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 425/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 4.0298e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 425: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 4.0209e-04 - mean_absolute_error: 0.0167 - val_loss: 2.2716e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 426/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.6278e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 426: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.6228e-04 - mean_absolute_error: 0.0158 - val_loss: 2.2612e-04 - val_mean_absolute_error: 0.0103\n",
      "Epoch 427/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 3.5087e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 427: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 3.5061e-04 - mean_absolute_error: 0.0158 - val_loss: 2.2282e-04 - val_mean_absolute_error: 0.0101\n",
      "Epoch 428/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 3.4249e-04 - mean_absolute_error: 0.0155\n",
      "Epoch 428: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.4224e-04 - mean_absolute_error: 0.0155 - val_loss: 2.2602e-04 - val_mean_absolute_error: 0.0103\n",
      "Epoch 429/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.5906e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 429: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - loss: 3.5871e-04 - mean_absolute_error: 0.0157 - val_loss: 2.3585e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 430/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 3.7933e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 430: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - loss: 3.7891e-04 - mean_absolute_error: 0.0161 - val_loss: 2.4480e-04 - val_mean_absolute_error: 0.0116\n",
      "Epoch 431/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.5933e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 431: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 3.5894e-04 - mean_absolute_error: 0.0160 - val_loss: 2.3184e-04 - val_mean_absolute_error: 0.0101\n",
      "Epoch 432/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 3.5090e-04 - mean_absolute_error: 0.0155\n",
      "Epoch 432: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 3.5036e-04 - mean_absolute_error: 0.0155 - val_loss: 2.2756e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 433/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 3.5832e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 433: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 3.5789e-04 - mean_absolute_error: 0.0157 - val_loss: 2.5519e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 434/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.7549e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 434: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.7493e-04 - mean_absolute_error: 0.0161 - val_loss: 2.2671e-04 - val_mean_absolute_error: 0.0102\n",
      "Epoch 435/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 3.7383e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 435: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 3.7302e-04 - mean_absolute_error: 0.0160 - val_loss: 2.2847e-04 - val_mean_absolute_error: 0.0107\n",
      "Epoch 436/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 3.5118e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 436: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 3.5071e-04 - mean_absolute_error: 0.0157 - val_loss: 2.3572e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 437/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.4912e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 437: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.4893e-04 - mean_absolute_error: 0.0158 - val_loss: 2.5019e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 438/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 3.7978e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 438: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 3.7898e-04 - mean_absolute_error: 0.0161 - val_loss: 2.3870e-04 - val_mean_absolute_error: 0.0105\n",
      "Epoch 439/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.9651e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 439: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.9554e-04 - mean_absolute_error: 0.0166 - val_loss: 2.3790e-04 - val_mean_absolute_error: 0.0116\n",
      "Epoch 440/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.8938e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 440: val_loss improved from 0.00022 to 0.00022, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.8871e-04 - mean_absolute_error: 0.0162 - val_loss: 2.2000e-04 - val_mean_absolute_error: 0.0099\n",
      "Epoch 441/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.8893e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 441: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.8809e-04 - mean_absolute_error: 0.0162 - val_loss: 2.8913e-04 - val_mean_absolute_error: 0.0120\n",
      "Epoch 442/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.7445e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 442: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.7398e-04 - mean_absolute_error: 0.0159 - val_loss: 2.3190e-04 - val_mean_absolute_error: 0.0102\n",
      "Epoch 443/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.6765e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 443: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 3.6718e-04 - mean_absolute_error: 0.0158 - val_loss: 2.2408e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 444/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.3853e-04 - mean_absolute_error: 0.0155\n",
      "Epoch 444: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.3837e-04 - mean_absolute_error: 0.0154 - val_loss: 2.2749e-04 - val_mean_absolute_error: 0.0107\n",
      "Epoch 445/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.5763e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 445: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.5705e-04 - mean_absolute_error: 0.0157 - val_loss: 2.4102e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 446/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.8871e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 446: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 3.8821e-04 - mean_absolute_error: 0.0163 - val_loss: 2.8540e-04 - val_mean_absolute_error: 0.0129\n",
      "Epoch 447/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.9099e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 447: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.9020e-04 - mean_absolute_error: 0.0164 - val_loss: 2.2904e-04 - val_mean_absolute_error: 0.0119\n",
      "Epoch 448/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.5955e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 448: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.5921e-04 - mean_absolute_error: 0.0161 - val_loss: 2.3616e-04 - val_mean_absolute_error: 0.0116\n",
      "Epoch 449/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.6290e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 449: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.6241e-04 - mean_absolute_error: 0.0157 - val_loss: 2.5613e-04 - val_mean_absolute_error: 0.0110\n",
      "Epoch 450/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.7515e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 450: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.7460e-04 - mean_absolute_error: 0.0161 - val_loss: 2.2288e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 451/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.5970e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 451: val_loss improved from 0.00022 to 0.00022, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.5902e-04 - mean_absolute_error: 0.0159 - val_loss: 2.1955e-04 - val_mean_absolute_error: 0.0105\n",
      "Epoch 452/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.7581e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 452: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.7507e-04 - mean_absolute_error: 0.0163 - val_loss: 2.3171e-04 - val_mean_absolute_error: 0.0105\n",
      "Epoch 453/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.9219e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 453: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.9134e-04 - mean_absolute_error: 0.0161 - val_loss: 2.2529e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 454/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.7267e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 454: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.7234e-04 - mean_absolute_error: 0.0158 - val_loss: 2.4190e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 455/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.7727e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 455: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.7661e-04 - mean_absolute_error: 0.0160 - val_loss: 2.2248e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 456/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.6154e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 456: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.6104e-04 - mean_absolute_error: 0.0159 - val_loss: 2.4249e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 457/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 3.6460e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 457: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 3.6427e-04 - mean_absolute_error: 0.0158 - val_loss: 2.4123e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 458/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.6942e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 458: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.6886e-04 - mean_absolute_error: 0.0162 - val_loss: 2.8019e-04 - val_mean_absolute_error: 0.0126\n",
      "Epoch 459/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.9774e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 459: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.9698e-04 - mean_absolute_error: 0.0165 - val_loss: 2.2280e-04 - val_mean_absolute_error: 0.0105\n",
      "Epoch 460/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.7498e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 460: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.7441e-04 - mean_absolute_error: 0.0159 - val_loss: 2.2553e-04 - val_mean_absolute_error: 0.0105\n",
      "Epoch 461/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 3.9264e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 461: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 127ms/step - loss: 3.9183e-04 - mean_absolute_error: 0.0163 - val_loss: 2.2435e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 462/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 3.6632e-04 - mean_absolute_error: 0.0155\n",
      "Epoch 462: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - loss: 3.6592e-04 - mean_absolute_error: 0.0155 - val_loss: 2.3420e-04 - val_mean_absolute_error: 0.0109\n",
      "Epoch 463/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.5337e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 463: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.5298e-04 - mean_absolute_error: 0.0157 - val_loss: 2.5306e-04 - val_mean_absolute_error: 0.0105\n",
      "Epoch 464/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.7609e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 464: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.7561e-04 - mean_absolute_error: 0.0162 - val_loss: 2.9163e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 465/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.8803e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 465: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.8699e-04 - mean_absolute_error: 0.0163 - val_loss: 2.3188e-04 - val_mean_absolute_error: 0.0102\n",
      "Epoch 466/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 3.7069e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 466: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - loss: 3.7016e-04 - mean_absolute_error: 0.0156 - val_loss: 2.2680e-04 - val_mean_absolute_error: 0.0101\n",
      "Epoch 467/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 3.6950e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 467: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 3.6903e-04 - mean_absolute_error: 0.0161 - val_loss: 2.4269e-04 - val_mean_absolute_error: 0.0109\n",
      "Epoch 468/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 4.0154e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 468: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 4.0051e-04 - mean_absolute_error: 0.0166 - val_loss: 2.6203e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 469/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 3.9672e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 469: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 127ms/step - loss: 3.9573e-04 - mean_absolute_error: 0.0162 - val_loss: 2.8267e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 470/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 3.6832e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 470: val_loss improved from 0.00022 to 0.00022, saving model to results\\2025-08-21_AMZN-sh-1-sc-1-sbd-0-huber-adam-LSTM-seq-50-step-15-layers-2-units-256.weights.h5\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - loss: 3.6769e-04 - mean_absolute_error: 0.0159 - val_loss: 2.1946e-04 - val_mean_absolute_error: 0.0105\n",
      "Epoch 471/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.7443e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 471: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 3.7385e-04 - mean_absolute_error: 0.0162 - val_loss: 2.2552e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 472/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 3.8544e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 472: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 127ms/step - loss: 3.8501e-04 - mean_absolute_error: 0.0162 - val_loss: 2.5230e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 473/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 3.7560e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 473: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - loss: 3.7483e-04 - mean_absolute_error: 0.0158 - val_loss: 2.2724e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 474/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.5374e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 474: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.5352e-04 - mean_absolute_error: 0.0156 - val_loss: 2.2752e-04 - val_mean_absolute_error: 0.0104\n",
      "Epoch 475/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 3.7042e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 475: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 3.6970e-04 - mean_absolute_error: 0.0160 - val_loss: 2.2877e-04 - val_mean_absolute_error: 0.0101\n",
      "Epoch 476/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 3.5749e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 476: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 3.5707e-04 - mean_absolute_error: 0.0158 - val_loss: 2.5865e-04 - val_mean_absolute_error: 0.0107\n",
      "Epoch 477/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 3.8358e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 477: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 3.8292e-04 - mean_absolute_error: 0.0159 - val_loss: 2.2356e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 478/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.7119e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 478: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 3.7049e-04 - mean_absolute_error: 0.0161 - val_loss: 2.2980e-04 - val_mean_absolute_error: 0.0102\n",
      "Epoch 479/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 3.5207e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 479: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 127ms/step - loss: 3.5157e-04 - mean_absolute_error: 0.0157 - val_loss: 2.3358e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 480/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 3.6113e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 480: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 3.6052e-04 - mean_absolute_error: 0.0158 - val_loss: 2.3363e-04 - val_mean_absolute_error: 0.0114\n",
      "Epoch 481/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.6544e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 481: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.6484e-04 - mean_absolute_error: 0.0158 - val_loss: 2.3193e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 482/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 3.6364e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 482: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 3.6302e-04 - mean_absolute_error: 0.0158 - val_loss: 2.4396e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 483/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 3.7794e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 483: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 3.7715e-04 - mean_absolute_error: 0.0161 - val_loss: 2.3523e-04 - val_mean_absolute_error: 0.0103\n",
      "Epoch 484/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 3.6226e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 484: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 3.6194e-04 - mean_absolute_error: 0.0159 - val_loss: 2.3713e-04 - val_mean_absolute_error: 0.0108\n",
      "Epoch 485/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 3.6047e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 485: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - loss: 3.6031e-04 - mean_absolute_error: 0.0157 - val_loss: 2.5582e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 486/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 3.6121e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 486: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - loss: 3.6085e-04 - mean_absolute_error: 0.0160 - val_loss: 2.3500e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 487/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 3.6076e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 487: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 3.6009e-04 - mean_absolute_error: 0.0160 - val_loss: 2.2707e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 488/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 3.5167e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 488: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 3.5127e-04 - mean_absolute_error: 0.0157 - val_loss: 2.4613e-04 - val_mean_absolute_error: 0.0113\n",
      "Epoch 489/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 3.5457e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 489: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 3.5409e-04 - mean_absolute_error: 0.0156 - val_loss: 2.2630e-04 - val_mean_absolute_error: 0.0107\n",
      "Epoch 490/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.6892e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 490: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.6850e-04 - mean_absolute_error: 0.0160 - val_loss: 2.2656e-04 - val_mean_absolute_error: 0.0112\n",
      "Epoch 491/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.6543e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 491: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.6470e-04 - mean_absolute_error: 0.0160 - val_loss: 2.3606e-04 - val_mean_absolute_error: 0.0127\n",
      "Epoch 492/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.7156e-04 - mean_absolute_error: 0.0161\n",
      "Epoch 492: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.7104e-04 - mean_absolute_error: 0.0161 - val_loss: 2.3680e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 493/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 3.7346e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 493: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 3.7270e-04 - mean_absolute_error: 0.0157 - val_loss: 2.2164e-04 - val_mean_absolute_error: 0.0102\n",
      "Epoch 494/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3.4035e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 494: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.4010e-04 - mean_absolute_error: 0.0157 - val_loss: 2.2051e-04 - val_mean_absolute_error: 0.0100\n",
      "Epoch 495/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 3.7463e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 495: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 3.7414e-04 - mean_absolute_error: 0.0159 - val_loss: 2.2529e-04 - val_mean_absolute_error: 0.0102\n",
      "Epoch 496/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 3.6711e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 496: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 3.6664e-04 - mean_absolute_error: 0.0157 - val_loss: 2.2960e-04 - val_mean_absolute_error: 0.0111\n",
      "Epoch 497/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.5258e-04 - mean_absolute_error: 0.0154\n",
      "Epoch 497: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.5205e-04 - mean_absolute_error: 0.0154 - val_loss: 2.2657e-04 - val_mean_absolute_error: 0.0109\n",
      "Epoch 498/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.4850e-04 - mean_absolute_error: 0.0155\n",
      "Epoch 498: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 3.4830e-04 - mean_absolute_error: 0.0155 - val_loss: 2.3135e-04 - val_mean_absolute_error: 0.0102\n",
      "Epoch 499/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 3.6442e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 499: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - loss: 3.6399e-04 - mean_absolute_error: 0.0159 - val_loss: 2.3035e-04 - val_mean_absolute_error: 0.0102\n",
      "Epoch 500/500\n",
      "\u001b[1m88/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 3.5564e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 500: val_loss did not improve from 0.00022\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 3.5500e-04 - mean_absolute_error: 0.0156 - val_loss: 2.2122e-04 - val_mean_absolute_error: 0.0107\n"
     ]
    }
   ],
   "source": [
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".weights.h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, pred_future, true_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, pred_future, true_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".weights.h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step\n"
     ]
    }
   ],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    }
   ],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 15 days is 213.60$\n",
      "huber loss: 0.00021945823391433805\n",
      "Mean Absolute Error: 2.6137072941682273\n",
      "Accuracy score: 0.5326241134751774\n",
      "Total buy profit: 1107.301044344902\n",
      "Total sell profit: 279.95274183899164\n",
      "Total profit: 1387.2537861838937\n",
      "Profit per trade: 0.9838679334637543\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adjclose_15</th>\n",
       "      <th>true_adjclose_15</th>\n",
       "      <th>buy_profit</th>\n",
       "      <th>sell_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-08-04</th>\n",
       "      <td>0.118750</td>\n",
       "      <td>0.120573</td>\n",
       "      <td>0.115104</td>\n",
       "      <td>0.115625</td>\n",
       "      <td>0.115625</td>\n",
       "      <td>53424000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.257868</td>\n",
       "      <td>0.110938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-08-12</th>\n",
       "      <td>0.114063</td>\n",
       "      <td>0.115104</td>\n",
       "      <td>0.109896</td>\n",
       "      <td>0.109896</td>\n",
       "      <td>0.109896</td>\n",
       "      <td>11424000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.210097</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-08-18</th>\n",
       "      <td>0.102604</td>\n",
       "      <td>0.102604</td>\n",
       "      <td>0.098438</td>\n",
       "      <td>0.102083</td>\n",
       "      <td>0.102083</td>\n",
       "      <td>35688000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>0.161979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.059896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-08-22</th>\n",
       "      <td>0.105208</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.104688</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>14256000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.210050</td>\n",
       "      <td>0.154688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-08-26</th>\n",
       "      <td>0.111979</td>\n",
       "      <td>0.117708</td>\n",
       "      <td>0.111458</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>51480000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.235054</td>\n",
       "      <td>0.170313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.053125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-09-04</th>\n",
       "      <td>0.118229</td>\n",
       "      <td>0.127604</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.127604</td>\n",
       "      <td>0.127604</td>\n",
       "      <td>66960000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.266119</td>\n",
       "      <td>0.203906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.076302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-09-08</th>\n",
       "      <td>0.126563</td>\n",
       "      <td>0.151042</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>112968000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.186828</td>\n",
       "      <td>0.202083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.052083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-09-15</th>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.183854</td>\n",
       "      <td>0.152604</td>\n",
       "      <td>0.154688</td>\n",
       "      <td>0.154688</td>\n",
       "      <td>111672000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.192944</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.051562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-09-16</th>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.155990</td>\n",
       "      <td>0.167708</td>\n",
       "      <td>0.167708</td>\n",
       "      <td>128640000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.312967</td>\n",
       "      <td>0.202865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.035157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-10-01</th>\n",
       "      <td>0.221875</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.196875</td>\n",
       "      <td>0.201042</td>\n",
       "      <td>0.201042</td>\n",
       "      <td>99984000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.339536</td>\n",
       "      <td>0.226042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-10-06</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>0.197135</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>40560000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.047873</td>\n",
       "      <td>0.213542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-10-24</th>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.253125</td>\n",
       "      <td>0.227083</td>\n",
       "      <td>0.251302</td>\n",
       "      <td>0.251302</td>\n",
       "      <td>189840000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.185685</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-10-28</th>\n",
       "      <td>0.195833</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.193750</td>\n",
       "      <td>0.247396</td>\n",
       "      <td>0.247396</td>\n",
       "      <td>234384000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.259159</td>\n",
       "      <td>0.220833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-11-03</th>\n",
       "      <td>0.260938</td>\n",
       "      <td>0.260938</td>\n",
       "      <td>0.247396</td>\n",
       "      <td>0.253646</td>\n",
       "      <td>0.253646</td>\n",
       "      <td>39984000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.056960</td>\n",
       "      <td>0.211458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-11-04</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.252604</td>\n",
       "      <td>0.241146</td>\n",
       "      <td>0.247917</td>\n",
       "      <td>0.247917</td>\n",
       "      <td>47304000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.114460</td>\n",
       "      <td>0.210156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-11-12</th>\n",
       "      <td>0.188802</td>\n",
       "      <td>0.209375</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.188542</td>\n",
       "      <td>0.188542</td>\n",
       "      <td>173664000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.338064</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.036458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-11-26</th>\n",
       "      <td>0.211979</td>\n",
       "      <td>0.220573</td>\n",
       "      <td>0.211979</td>\n",
       "      <td>0.213021</td>\n",
       "      <td>0.213021</td>\n",
       "      <td>32616000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.095612</td>\n",
       "      <td>0.214583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-12-18</th>\n",
       "      <td>0.217708</td>\n",
       "      <td>0.221354</td>\n",
       "      <td>0.211458</td>\n",
       "      <td>0.214583</td>\n",
       "      <td>0.214583</td>\n",
       "      <td>64080000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.215398</td>\n",
       "      <td>0.215104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-06</th>\n",
       "      <td>0.234896</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.241927</td>\n",
       "      <td>0.241927</td>\n",
       "      <td>83496000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.146117</td>\n",
       "      <td>0.238542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-08</th>\n",
       "      <td>0.234896</td>\n",
       "      <td>0.235156</td>\n",
       "      <td>0.226563</td>\n",
       "      <td>0.230729</td>\n",
       "      <td>0.230729</td>\n",
       "      <td>120312000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.224784</td>\n",
       "      <td>0.245833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.015104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                open      high       low     close  adjclose     volume  \\\n",
       "1997-08-04  0.118750  0.120573  0.115104  0.115625  0.115625   53424000   \n",
       "1997-08-12  0.114063  0.115104  0.109896  0.109896  0.109896   11424000   \n",
       "1997-08-18  0.102604  0.102604  0.098438  0.102083  0.102083   35688000   \n",
       "1997-08-22  0.105208  0.106250  0.104688  0.106250  0.106250   14256000   \n",
       "1997-08-26  0.111979  0.117708  0.111458  0.117188  0.117188   51480000   \n",
       "1997-09-04  0.118229  0.127604  0.117188  0.127604  0.127604   66960000   \n",
       "1997-09-08  0.126563  0.151042  0.125000  0.150000  0.150000  112968000   \n",
       "1997-09-15  0.183333  0.183854  0.152604  0.154688  0.154688  111672000   \n",
       "1997-09-16  0.156250  0.177083  0.155990  0.167708  0.167708  128640000   \n",
       "1997-10-01  0.221875  0.225000  0.196875  0.201042  0.201042   99984000   \n",
       "1997-10-06  0.200000  0.206250  0.197135  0.206250  0.206250   40560000   \n",
       "1997-10-24  0.237500  0.253125  0.227083  0.251302  0.251302  189840000   \n",
       "1997-10-28  0.195833  0.250000  0.193750  0.247396  0.247396  234384000   \n",
       "1997-11-03  0.260938  0.260938  0.247396  0.253646  0.253646   39984000   \n",
       "1997-11-04  0.250000  0.252604  0.241146  0.247917  0.247917   47304000   \n",
       "1997-11-12  0.188802  0.209375  0.183333  0.188542  0.188542  173664000   \n",
       "1997-11-26  0.211979  0.220573  0.211979  0.213021  0.213021   32616000   \n",
       "1997-12-18  0.217708  0.221354  0.211458  0.214583  0.214583   64080000   \n",
       "1998-01-06  0.234896  0.243750  0.233333  0.241927  0.241927   83496000   \n",
       "1998-01-08  0.234896  0.235156  0.226563  0.230729  0.230729  120312000   \n",
       "\n",
       "           ticker  adjclose_15  true_adjclose_15  buy_profit  sell_profit  \n",
       "1997-08-04   AMZN    -0.257868          0.110938         0.0     0.004687  \n",
       "1997-08-12   AMZN    -0.210097          0.116667         0.0    -0.006771  \n",
       "1997-08-18   AMZN    -0.253852          0.161979         0.0    -0.059896  \n",
       "1997-08-22   AMZN    -0.210050          0.154688         0.0    -0.048438  \n",
       "1997-08-26   AMZN    -0.235054          0.170313         0.0    -0.053125  \n",
       "1997-09-04   AMZN    -0.266119          0.203906         0.0    -0.076302  \n",
       "1997-09-08   AMZN    -0.186828          0.202083         0.0    -0.052083  \n",
       "1997-09-15   AMZN    -0.192944          0.206250         0.0    -0.051562  \n",
       "1997-09-16   AMZN    -0.312967          0.202865         0.0    -0.035157  \n",
       "1997-10-01   AMZN    -0.339536          0.226042         0.0    -0.025000  \n",
       "1997-10-06   AMZN    -0.047873          0.213542         0.0    -0.007292  \n",
       "1997-10-24   AMZN    -0.185685          0.208333         0.0     0.042969  \n",
       "1997-10-28   AMZN    -0.259159          0.220833         0.0     0.026563  \n",
       "1997-11-03   AMZN    -0.056960          0.211458         0.0     0.042188  \n",
       "1997-11-04   AMZN    -0.114460          0.210156         0.0     0.037761  \n",
       "1997-11-12   AMZN    -0.338064          0.225000         0.0    -0.036458  \n",
       "1997-11-26   AMZN    -0.095612          0.214583         0.0    -0.001562  \n",
       "1997-12-18   AMZN    -0.215398          0.215104         0.0    -0.000521  \n",
       "1998-01-06   AMZN    -0.146117          0.238542         0.0     0.003385  \n",
       "1998-01-08   AMZN    -0.224784          0.245833         0.0    -0.015104  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adjclose_15</th>\n",
       "      <th>true_adjclose_15</th>\n",
       "      <th>buy_profit</th>\n",
       "      <th>sell_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-03-10</th>\n",
       "      <td>195.600006</td>\n",
       "      <td>196.729996</td>\n",
       "      <td>190.850006</td>\n",
       "      <td>194.539993</td>\n",
       "      <td>194.539993</td>\n",
       "      <td>62350900</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>185.134689</td>\n",
       "      <td>190.259995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.279999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-11</th>\n",
       "      <td>193.899994</td>\n",
       "      <td>200.179993</td>\n",
       "      <td>193.399994</td>\n",
       "      <td>196.589996</td>\n",
       "      <td>196.589996</td>\n",
       "      <td>54002900</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>186.110626</td>\n",
       "      <td>192.169998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.419998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-13</th>\n",
       "      <td>198.169998</td>\n",
       "      <td>198.880005</td>\n",
       "      <td>191.820007</td>\n",
       "      <td>193.889999</td>\n",
       "      <td>193.889999</td>\n",
       "      <td>41270800</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>187.017075</td>\n",
       "      <td>178.410004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.479996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-14</th>\n",
       "      <td>197.410004</td>\n",
       "      <td>198.649994</td>\n",
       "      <td>195.320007</td>\n",
       "      <td>197.949997</td>\n",
       "      <td>197.949997</td>\n",
       "      <td>38096700</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>187.425552</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-17</th>\n",
       "      <td>198.770004</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>194.320007</td>\n",
       "      <td>195.740005</td>\n",
       "      <td>195.740005</td>\n",
       "      <td>47341800</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>186.966766</td>\n",
       "      <td>175.259995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.480011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-24</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>203.639999</td>\n",
       "      <td>199.949997</td>\n",
       "      <td>203.259995</td>\n",
       "      <td>203.259995</td>\n",
       "      <td>41625400</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>190.607010</td>\n",
       "      <td>182.119995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.139999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-26</th>\n",
       "      <td>205.839996</td>\n",
       "      <td>206.009995</td>\n",
       "      <td>199.929993</td>\n",
       "      <td>201.130005</td>\n",
       "      <td>201.130005</td>\n",
       "      <td>32855300</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>191.645218</td>\n",
       "      <td>174.330002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-08</th>\n",
       "      <td>185.229996</td>\n",
       "      <td>185.899994</td>\n",
       "      <td>168.570007</td>\n",
       "      <td>170.660004</td>\n",
       "      <td>170.660004</td>\n",
       "      <td>87710400</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>183.818756</td>\n",
       "      <td>184.419998</td>\n",
       "      <td>13.759995</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-09</th>\n",
       "      <td>172.119995</td>\n",
       "      <td>192.649994</td>\n",
       "      <td>169.929993</td>\n",
       "      <td>191.100006</td>\n",
       "      <td>191.100006</td>\n",
       "      <td>116804300</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>190.110992</td>\n",
       "      <td>190.199997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-10</th>\n",
       "      <td>185.440002</td>\n",
       "      <td>186.869995</td>\n",
       "      <td>175.850006</td>\n",
       "      <td>181.220001</td>\n",
       "      <td>181.220001</td>\n",
       "      <td>68302000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>190.644821</td>\n",
       "      <td>189.979996</td>\n",
       "      <td>8.759995</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-21</th>\n",
       "      <td>169.600006</td>\n",
       "      <td>169.600006</td>\n",
       "      <td>165.289993</td>\n",
       "      <td>167.320007</td>\n",
       "      <td>167.320007</td>\n",
       "      <td>48126100</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>192.428665</td>\n",
       "      <td>208.639999</td>\n",
       "      <td>41.319992</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-14</th>\n",
       "      <td>211.449997</td>\n",
       "      <td>211.929993</td>\n",
       "      <td>208.850006</td>\n",
       "      <td>210.250000</td>\n",
       "      <td>210.250000</td>\n",
       "      <td>38492100</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>212.875061</td>\n",
       "      <td>207.910004</td>\n",
       "      <td>-2.339996</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-27</th>\n",
       "      <td>203.089996</td>\n",
       "      <td>206.690002</td>\n",
       "      <td>202.190002</td>\n",
       "      <td>206.020004</td>\n",
       "      <td>206.020004</td>\n",
       "      <td>34892000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>215.812164</td>\n",
       "      <td>214.820007</td>\n",
       "      <td>8.800003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-06</th>\n",
       "      <td>212.399994</td>\n",
       "      <td>213.869995</td>\n",
       "      <td>210.500000</td>\n",
       "      <td>213.570007</td>\n",
       "      <td>213.570007</td>\n",
       "      <td>39832500</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>220.092499</td>\n",
       "      <td>219.389999</td>\n",
       "      <td>5.819992</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-23</th>\n",
       "      <td>209.789993</td>\n",
       "      <td>210.389999</td>\n",
       "      <td>207.309998</td>\n",
       "      <td>208.470001</td>\n",
       "      <td>208.470001</td>\n",
       "      <td>37311700</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>227.154755</td>\n",
       "      <td>226.350006</td>\n",
       "      <td>17.880005</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-01</th>\n",
       "      <td>219.500000</td>\n",
       "      <td>221.880005</td>\n",
       "      <td>217.929993</td>\n",
       "      <td>220.460007</td>\n",
       "      <td>220.460007</td>\n",
       "      <td>39256800</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>229.027313</td>\n",
       "      <td>228.289993</td>\n",
       "      <td>7.829987</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-07</th>\n",
       "      <td>223.000000</td>\n",
       "      <td>224.289993</td>\n",
       "      <td>222.369995</td>\n",
       "      <td>223.470001</td>\n",
       "      <td>223.470001</td>\n",
       "      <td>36604100</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>229.179001</td>\n",
       "      <td>232.789993</td>\n",
       "      <td>9.319992</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-18</th>\n",
       "      <td>225.139999</td>\n",
       "      <td>226.399994</td>\n",
       "      <td>222.979996</td>\n",
       "      <td>226.130005</td>\n",
       "      <td>226.130005</td>\n",
       "      <td>37833800</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>228.218887</td>\n",
       "      <td>222.690002</td>\n",
       "      <td>-3.440002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-25</th>\n",
       "      <td>232.220001</td>\n",
       "      <td>232.479996</td>\n",
       "      <td>231.179993</td>\n",
       "      <td>231.440002</td>\n",
       "      <td>231.440002</td>\n",
       "      <td>28712100</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>227.699661</td>\n",
       "      <td>231.029999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-30</th>\n",
       "      <td>231.639999</td>\n",
       "      <td>231.800003</td>\n",
       "      <td>229.289993</td>\n",
       "      <td>230.190002</td>\n",
       "      <td>230.190002</td>\n",
       "      <td>32993300</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>228.381760</td>\n",
       "      <td>223.809998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.380005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close    adjclose  \\\n",
       "2025-03-10  195.600006  196.729996  190.850006  194.539993  194.539993   \n",
       "2025-03-11  193.899994  200.179993  193.399994  196.589996  196.589996   \n",
       "2025-03-13  198.169998  198.880005  191.820007  193.889999  193.889999   \n",
       "2025-03-14  197.410004  198.649994  195.320007  197.949997  197.949997   \n",
       "2025-03-17  198.770004  199.000000  194.320007  195.740005  195.740005   \n",
       "2025-03-24  200.000000  203.639999  199.949997  203.259995  203.259995   \n",
       "2025-03-26  205.839996  206.009995  199.929993  201.130005  201.130005   \n",
       "2025-04-08  185.229996  185.899994  168.570007  170.660004  170.660004   \n",
       "2025-04-09  172.119995  192.649994  169.929993  191.100006  191.100006   \n",
       "2025-04-10  185.440002  186.869995  175.850006  181.220001  181.220001   \n",
       "2025-04-21  169.600006  169.600006  165.289993  167.320007  167.320007   \n",
       "2025-05-14  211.449997  211.929993  208.850006  210.250000  210.250000   \n",
       "2025-05-27  203.089996  206.690002  202.190002  206.020004  206.020004   \n",
       "2025-06-06  212.399994  213.869995  210.500000  213.570007  213.570007   \n",
       "2025-06-23  209.789993  210.389999  207.309998  208.470001  208.470001   \n",
       "2025-07-01  219.500000  221.880005  217.929993  220.460007  220.460007   \n",
       "2025-07-07  223.000000  224.289993  222.369995  223.470001  223.470001   \n",
       "2025-07-18  225.139999  226.399994  222.979996  226.130005  226.130005   \n",
       "2025-07-25  232.220001  232.479996  231.179993  231.440002  231.440002   \n",
       "2025-07-30  231.639999  231.800003  229.289993  230.190002  230.190002   \n",
       "\n",
       "               volume ticker  adjclose_15  true_adjclose_15  buy_profit  \\\n",
       "2025-03-10   62350900   AMZN   185.134689        190.259995    0.000000   \n",
       "2025-03-11   54002900   AMZN   186.110626        192.169998    0.000000   \n",
       "2025-03-13   41270800   AMZN   187.017075        178.410004    0.000000   \n",
       "2025-03-14   38096700   AMZN   187.425552        171.000000    0.000000   \n",
       "2025-03-17   47341800   AMZN   186.966766        175.259995    0.000000   \n",
       "2025-03-24   41625400   AMZN   190.607010        182.119995    0.000000   \n",
       "2025-03-26   32855300   AMZN   191.645218        174.330002    0.000000   \n",
       "2025-04-08   87710400   AMZN   183.818756        184.419998   13.759995   \n",
       "2025-04-09  116804300   AMZN   190.110992        190.199997    0.000000   \n",
       "2025-04-10   68302000   AMZN   190.644821        189.979996    8.759995   \n",
       "2025-04-21   48126100   AMZN   192.428665        208.639999   41.319992   \n",
       "2025-05-14   38492100   AMZN   212.875061        207.910004   -2.339996   \n",
       "2025-05-27   34892000   AMZN   215.812164        214.820007    8.800003   \n",
       "2025-06-06   39832500   AMZN   220.092499        219.389999    5.819992   \n",
       "2025-06-23   37311700   AMZN   227.154755        226.350006   17.880005   \n",
       "2025-07-01   39256800   AMZN   229.027313        228.289993    7.829987   \n",
       "2025-07-07   36604100   AMZN   229.179001        232.789993    9.319992   \n",
       "2025-07-18   37833800   AMZN   228.218887        222.690002   -3.440002   \n",
       "2025-07-25   28712100   AMZN   227.699661        231.029999    0.000000   \n",
       "2025-07-30   32993300   AMZN   228.381760        223.809998    0.000000   \n",
       "\n",
       "            sell_profit  \n",
       "2025-03-10     4.279999  \n",
       "2025-03-11     4.419998  \n",
       "2025-03-13    15.479996  \n",
       "2025-03-14    26.949997  \n",
       "2025-03-17    20.480011  \n",
       "2025-03-24    21.139999  \n",
       "2025-03-26    26.800003  \n",
       "2025-04-08     0.000000  \n",
       "2025-04-09     0.900009  \n",
       "2025-04-10     0.000000  \n",
       "2025-04-21     0.000000  \n",
       "2025-05-14     0.000000  \n",
       "2025-05-27     0.000000  \n",
       "2025-06-06     0.000000  \n",
       "2025-06-23     0.000000  \n",
       "2025-07-01     0.000000  \n",
       "2025-07-07     0.000000  \n",
       "2025-07-18     0.000000  \n",
       "2025-07-25     0.410004  \n",
       "2025-07-30     6.380005  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final dataframe to csv-results folder\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
